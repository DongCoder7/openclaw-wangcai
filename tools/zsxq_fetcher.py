#!/usr/bin/env python3
"""
çŸ¥è¯†æ˜Ÿçƒè°ƒç ”çºªè¦è·å–å·¥å…·
è‡ªåŠ¨è·å–"è°ƒç ”çºªè¦"æ˜Ÿçƒçš„æœ€æ–°å†…å®¹
"""
import requests
import json
import os
from datetime import datetime

# é…ç½®
GROUP_ID = "28855458518111"

# ä»ç¯å¢ƒå˜é‡è·å–cookiesï¼ˆé¿å…tokenç¡¬ç¼–ç ï¼‰
COOKIES = os.environ.get('ZSXQ_COOKIES', '')
if not COOKIES:
    # å°è¯•ä».envæ–‡ä»¶åŠ è½½
    env_path = os.path.join(os.path.dirname(__file__), '..', '.zsxq.env')
    if os.path.exists(env_path):
        with open(env_path, 'r') as f:
            for line in f:
                if line.startswith('ZSXQ_COOKIES='):
                    COOKIES = line.strip().split('=', 1)[1].strip('"\'')
                    break

if not COOKIES:
    raise ValueError("æœªæ‰¾åˆ°ZSXQ_COOKIESï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åˆ›å»º.zsxq.envæ–‡ä»¶")

BASE_URL = "https://api.zsxq.com/v2"
    
    Args:
        count: è·å–æ–‡ç« æ•°é‡ (æ³¨æ„: APIé™åˆ¶ï¼Œå•æ¬¡æœ€å¤šçº¦15æ¡)
        keyword: å…³é”®è¯ç­›é€‰ (å¯é€‰)
    
    Returns:
        list: æ–‡ç« åˆ—è¡¨
    """
    # APIå¯¹countæœ‰é™åˆ¶ï¼Œcount>15å¯èƒ½è¿”å›ç©º
    # é‡‡ç”¨åˆ†é¡µæ–¹å¼è·å–æ›´å¤šæ•°æ®
    all_topics = []
    per_page = 10  # æ¯é¡µè·å–æ•°é‡
    pages = (count + per_page - 1) // per_page  # è®¡ç®—éœ€è¦çš„é¡µæ•°
    
    headers = {
        "Cookie": COOKIES,
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept": "application/json"
    }
    
    for page in range(pages):
        url = f"{BASE_URL}/groups/{GROUP_ID}/topics?count={per_page}"
        
        try:
            response = requests.get(url, headers=headers, timeout=30)
            data = response.json()
            
            if not data.get('succeeded'):
                print(f"âš ï¸ ç¬¬{page+1}é¡µè·å–å¤±è´¥: {data.get('code', 'unknown')}")
                continue
            
            topics = data.get('resp_data', {}).get('topics', [])
            if not topics:
                break
                
            all_topics.extend(topics)
            
            # å¦‚æœè·å–åˆ°çš„è¯é¢˜å°‘äºper_pageï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šæ•°æ®äº†
            if len(topics) < per_page:
                break
                
        except Exception as e:
            print(f"âš ï¸ ç¬¬{page+1}é¡µè¯·æ±‚å¼‚å¸¸: {e}")
            continue
    
    print(f"âœ… å…±è·å– {len(all_topics)} æ¡è¯é¢˜")
    
    # å…³é”®è¯ç­›é€‰
    if keyword and all_topics:
        filtered = []
        keyword_lower = keyword.lower()
        for t in all_topics:
            text = t.get('talk', {}).get('text', '').lower()
            if keyword_lower in text:
                filtered.append(t)
        print(f"ğŸ” å…³é”®è¯'{keyword}'ç­›é€‰: {len(filtered)} æ¡åŒ¹é…")
        return filtered
    
    return all_topics

def format_topic(topic):
    """æ ¼å¼åŒ–å•ç¯‡æ–‡ç« """
    talk = topic.get('talk', {})
    text = talk.get('text', '')
    owner = talk.get('owner', {})
    
    return {
        'id': topic.get('topic_id'),
        'time': topic.get('create_time', '')[:16],
        'author': owner.get('name', 'æœªçŸ¥'),
        'text': text[:300] + '...' if len(text) > 300 else text,
        'read_count': topic.get('reading_count', 0),
        'like_count': topic.get('likes_count', 0)
    }

def search_industry_info(industry, count=10):
    """æœç´¢ç‰¹å®šè¡Œä¸šä¿¡æ¯
    
    Args:
        industry: è¡Œä¸šå…³é”®è¯ (å¦‚: å­˜å‚¨èŠ¯ç‰‡ã€åŠå¯¼ä½“ã€PCB)
        count: è·å–æ•°é‡
    
    Returns:
        list: ç›¸å…³æ–‡ç« 
    """
    print(f"ğŸ” æœç´¢ '{industry}' ç›¸å…³ä¿¡æ¯...")
    topics = get_topics(count=50, keyword=industry)
    
    if not topics:
        print(f"âš ï¸ æœªæ‰¾åˆ° '{industry}' ç›¸å…³å†…å®¹")
        return []
    
    print(f"âœ… æ‰¾åˆ° {len(topics)} æ¡ç›¸å…³å†…å®¹\n")
    
    results = []
    for t in topics[:count]:
        info = format_topic(t)
        results.append(info)
        print(f"ã€{info['time']}ã€‘ {info['author']}")
        print(f"{info['text']}")
        print(f"ğŸ“Š é˜…è¯»:{info['read_count']} | ğŸ‘ {info['like_count']}")
        print("-" * 60)
    
    return results

def get_latest(count=5):
    """è·å–æœ€æ–°æ–‡ç« """
    print(f"ğŸ“¥ è·å–æœ€æ–° {count} æ¡æ–‡ç« ...")
    topics = get_topics(count=count)
    
    if not topics:
        print("âŒ è·å–å¤±è´¥")
        return []
    
    results = []
    for t in topics:
        info = format_topic(t)
        results.append(info)
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("""
ç”¨æ³•:
  python3 zsxq_fetcher.py latest [æ•°é‡]     - è·å–æœ€æ–°æ–‡ç« 
  python3 zsxq_fetcher.py search <å…³é”®è¯>   - æœç´¢è¡Œä¸šä¿¡æ¯
  
ç¤ºä¾‹:
  python3 zsxq_fetcher.py latest 5
  python3 zsxq_fetcher.py search å­˜å‚¨èŠ¯ç‰‡
  python3 zsxq_fetcher.py search åŠå¯¼ä½“
        """)
        return
    
    command = sys.argv[1]
    
    if command == "latest":
        count = int(sys.argv[2]) if len(sys.argv) > 2 else 5
        results = get_latest(count)
        for r in results:
            print(f"ã€{r['time']}ã€‘ {r['author']}")
            print(f"{r['text']}")
            print(f"ğŸ“Š é˜…è¯»:{r['read_count']} | ğŸ‘ {r['like_count']}")
            print("-" * 60)
    
    elif command == "search":
        if len(sys.argv) < 3:
            print("âŒ è¯·æä¾›æœç´¢å…³é”®è¯")
            return
        keyword = sys.argv[2]
        search_industry_info(keyword)
    
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")

if __name__ == "__main__":
    main()
