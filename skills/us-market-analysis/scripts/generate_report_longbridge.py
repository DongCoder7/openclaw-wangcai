#!/usr/bin/env python3
"""
ç¾è‚¡å¸‚åœºæ·±åº¦åˆ†æ - é•¿æ¡¥APIç‰ˆ (v2.0)
æ¯æ—¥ç”Ÿæˆç¾è‚¡æ¿å—ã€ä¸ªè‚¡è¡Œæƒ…æŠ¥å‘Š

æ•°æ®æºè¯´æ˜ï¼ˆä¸¥æ ¼æ ‡æ³¨ï¼‰ï¼š
- ä¸ªè‚¡è¡Œæƒ…: é•¿æ¡¥API (Longbridge OpenAPI)
- ä¸ªè‚¡å¸‚å€¼: é•¿æ¡¥APIé™æ€æ•°æ® (æ€»è‚¡æœ¬Ã—å½“å‰è‚¡ä»·)
- ç¾è‚¡æŒ‡æ•°: è…¾è®¯è´¢ç»API (qt.gtimg.cn)
- æ¶¨è·Œå¹…è®¡ç®—: (ç°ä»·-æ˜¨æ”¶)/æ˜¨æ”¶ Ã— 100%

åˆ†ææ¡†æ¶ï¼š
1. ä¸»è¦æŒ‡æ•°è¡¨ç°ï¼ˆé“ç¼æ–¯ã€çº³æ–¯è¾¾å…‹ã€æ ‡æ™®500ï¼‰
2. æ¿å—å¼ºå¼±æ’åºï¼ˆå¸‚å€¼>500äº¿ç¾å…ƒï¼‰
3. æ ¸å¿ƒé©±åŠ¨å› å­è¯†åˆ«
4. ç¾è‚¡â†’Aè‚¡ä¼ å¯¼é€»è¾‘
5. åº”å¯¹ç­–ç•¥å»ºè®®
6. å¸‚åœºå±•æœ›ä¸é£é™©æç¤º

ä½œè€…: è±†å¥¶æŠ•èµ„ç­–ç•¥ç³»ç»Ÿ
ç‰ˆæœ¬: 2.0
"""
import sys
import os
import json
from datetime import datetime, timedelta

# æ·»åŠ è·¯å¾„
sys.path.insert(0, '/root/.openclaw/workspace/tools')
from longbridge_api import get_longbridge_api

# ============================================
# æ•°æ®æºé…ç½®
# ============================================

# ä¸»è¦æŒ‡æ•° (è…¾è®¯è´¢ç»APIä»£ç )
# æ•°æ®æº: è…¾è®¯è´¢ç» https://qt.gtimg.cn
INDICES = {
    'usDJI': {'name': 'é“ç¼æ–¯', 'source': 'è…¾è®¯è´¢ç»API'},
    'usIXIC': {'name': 'çº³æ–¯è¾¾å…‹', 'source': 'è…¾è®¯è´¢ç»API'},
    'usINX': {'name': 'æ ‡æ™®500', 'source': 'è…¾è®¯è´¢ç»API'}
}

# ç¾è‚¡æ¿å—å®šä¹‰ - å«å¸‚å€¼ç­›é€‰åŸºå‡†
# æ•°æ®æº: é•¿æ¡¥API (è¡Œæƒ…+é™æ€æ•°æ®)
US_SECTORS = {
    'AIç®—åŠ›': {
        'stocks': ['NVDA.US', 'AVGO.US', 'AMD.US', 'MRVL.US', 'SMCI.US', 'ARM.US', 'PLTR.US'],
        'a_share_map': ['å¯’æ­¦çºª', 'æµ·å…‰ä¿¡æ¯', 'æµªæ½®ä¿¡æ¯', 'ä¸­ç§‘æ›™å…‰'],
        'source': 'é•¿æ¡¥API'
    },
    'åŠå¯¼ä½“': {
        'stocks': ['NVDA.US', 'AMD.US', 'INTC.US', 'TSM.US', 'ASML.US', 'AMAT.US', 'LRCX.US', 'KLAC.US', 'QCOM.US'],
        'a_share_map': ['ä¸­èŠ¯å›½é™…', 'åŒ—æ–¹ååˆ›', 'ä¸­å¾®å…¬å¸', 'æ‹“è†ç§‘æŠ€'],
        'source': 'é•¿æ¡¥API'
    },
    'ç§‘æŠ€å·¨å¤´': {
        'stocks': ['AAPL.US', 'MSFT.US', 'GOOGL.US', 'META.US', 'AMZN.US', 'TSLA.US', 'NFLX.US'],
        'a_share_map': ['å°ç±³é›†å›¢', 'ç¾å›¢', 'æ¯”äºšè¿ª', 'ç«‹è®¯ç²¾å¯†'],
        'source': 'é•¿æ¡¥API'
    },
    'å…‰é€šè®¯': {
        'stocks': ['ANET.US', 'LITE.US', 'CIEN.US', 'NPTN.US', 'AAOI.US'],
        'a_share_map': ['ä¸­é™…æ—­åˆ›', 'æ–°æ˜“ç››', 'å¤©å­šé€šä¿¡', 'å…‰è¿…ç§‘æŠ€'],
        'source': 'é•¿æ¡¥API'
    },
    'ç”Ÿç‰©åŒ»è¯': {
        'stocks': ['LLY.US', 'NVO.US', 'JNJ.US', 'PFE.US', 'MRK.US', 'UNH.US', 'ABBV.US'],
        'a_share_map': ['æ’ç‘åŒ»è¯', 'è¿ˆç‘åŒ»ç–—', 'è¯æ˜åº·å¾·', 'ç™¾æµç¥å·'],
        'source': 'é•¿æ¡¥API'
    },
    'å­˜å‚¨/æ•°æ®ä¸­å¿ƒ': {
        'stocks': ['WDC.US', 'STX.US', 'SNOW.US', 'NET.US', 'DDOG.US', 'CRWD.US'],
        'a_share_map': ['å…†æ˜“åˆ›æ–°', 'æ¾œèµ·ç§‘æŠ€', 'ç´«å…‰å›½å¾®', 'æ±Ÿæ³¢é¾™'],
        'source': 'é•¿æ¡¥API'
    },
    'èƒ½æº': {
        'stocks': ['XOM.US', 'CVX.US', 'COP.US', 'OXY.US', 'SLB.US', 'BP.US'],
        'a_share_map': ['ä¸­å›½çŸ³æ²¹', 'ä¸­å›½æµ·æ²¹', 'ä¸­å›½çŸ³åŒ–', 'é™•è¥¿ç…¤ä¸š'],
        'source': 'é•¿æ¡¥API'
    },
    'é‡‘è': {
        'stocks': ['V.US', 'MA.US', 'JPM.US', 'BAC.US', 'GS.US', 'MS.US', 'WFC.US'],
        'a_share_map': ['æ‹›å•†é“¶è¡Œ', 'ä¸­å›½å¹³å®‰', 'ä¸œæ–¹è´¢å¯Œ', 'ä¸­ä¿¡è¯åˆ¸'],
        'source': 'é•¿æ¡¥API'
    },
    'æ¶ˆè´¹': {
        'stocks': ['WMT.US', 'COST.US', 'HD.US', 'NKE.US', 'MCD.US', 'SBUX.US', 'KO.US'],
        'a_share_map': ['è´µå·èŒ…å°', 'äº”ç²®æ¶²', 'ç¾çš„é›†å›¢', 'ä¼Šåˆ©è‚¡ä»½'],
        'source': 'é•¿æ¡¥API'
    },
    'ä¸­æ¦‚äº’è”': {
        'stocks': ['BABA.US', 'JD.US', 'PDD.US', 'NIO.US', 'LI.US', 'XPEV.US', 'TME.US', 'DIDI.US'],
        'a_share_map': ['é˜¿é‡Œå·´å·´', 'äº¬ä¸œ', 'æ‹¼å¤šå¤š', 'è”šæ¥'],
        'source': 'é•¿æ¡¥API'
    }
}

# ç”¨æˆ·ID
USER_ID = 'ou_efbad805767f4572e8f93ebafa8d5402'

# å¸‚å€¼è¿‡æ»¤é˜ˆå€¼ï¼ˆäº¿ç¾å…ƒï¼‰
MARKET_CAP_THRESHOLD = 500


def format_change(value):
    """æ ¼å¼åŒ–æ¶¨è·Œå¹…"""
    try:
        change = float(value)
        return f"+{change:.2f}%" if change > 0 else f"{change:.2f}%"
    except:
        return "--"


def get_emoji(change):
    """æ ¹æ®æ¶¨è·Œå¹…è¿”å›è¡¨æƒ…"""
    try:
        c = float(change)
        if c > 3:
            return "ğŸš€"
        elif c > 0:
            return "ğŸ“ˆ"
        elif c > -3:
            return "ğŸ“‰"
        else:
            return "ğŸ”»"
    except:
        return "âšª"


def get_importance_emoji(change):
    """é‡è¦åº¦è¯„çº§"""
    try:
        c = abs(float(change))
        if c > 5:
            return "â­â­â­ é«˜"
        elif c > 2:
            return "â­â­ ä¸­"
        else:
            return "â­ ä½"
    except:
        return "-"


def get_rank_emoji(rank):
    """æ’åè¡¨æƒ…"""
    if rank == 1:
        return "ğŸ¥‡"
    elif rank == 2:
        return "ğŸ¥ˆ"
    elif rank == 3:
        return "ğŸ¥‰"
    else:
        return f"{rank}."


def get_action_emoji(change):
    """æ“ä½œå»ºè®®è¡¨æƒ…"""
    try:
        c = float(change)
        if c > 3:
            return "âœ… å…³æ³¨", "å¼ºåŠ¿ä¸Šæ¶¨ï¼Œå¯æ‹©æœºå‚ä¸"
        elif c > 0:
            return "â¡ï¸ æŒæœ‰", "èµ°åŠ¿å¹³ç¨³ï¼Œç»´æŒä»“ä½"
        elif c > -3:
            return "âš ï¸ è§‚æœ›", "çŸ­æœŸè°ƒæ•´ï¼Œç­‰å¾…ä¼ç¨³"
        else:
            return "âŒ è§„é¿", "å¤§å¹…ä¸‹è·Œï¼Œæš‚æ—¶å›é¿"
    except:
        return "-", "-"


def send_feishu_message(content: str, title: str = "ç¾è‚¡æŠ¥å‘Š"):
    """å‘é€é£ä¹¦æ¶ˆæ¯"""
    try:
        import subprocess
        result = subprocess.run([
            'openclaw', 'message', 'send',
            '--channel', 'feishu',
            '--target', USER_ID,
            '--message', content
        ], capture_output=True, text=True)

        if result.returncode == 0:
            print("âœ… é£ä¹¦æ¶ˆæ¯å·²å‘é€")
            return True
        else:
            print(f"âš ï¸ é£ä¹¦å‘é€å¤±è´¥: {result.stderr[:200]}")
            return False
    except Exception as e:
        print(f"âš ï¸ é£ä¹¦å‘é€å¼‚å¸¸: {e}")
        return False


def get_us_index_quote(symbol):
    """
    è·å–ç¾è‚¡æŒ‡æ•°è¡Œæƒ…
    æ•°æ®æº: è…¾è®¯è´¢ç»API (https://qt.gtimg.cn)
    """
    try:
        import requests
        url = f"https://qt.gtimg.cn/q={symbol}"
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            text = response.text
            if '"' in text and 'none_match' not in text:
                inner = text.split('"')[1]
                parts = inner.split('~')
                if len(parts) > 32:
                    name = parts[1] if len(parts) > 1 else symbol
                    price = float(parts[3]) if len(parts) > 3 else 0
                    change = float(parts[32]) if len(parts) > 32 else 0
                    return {
                        'symbol': symbol,
                        'name': name,
                        'price': price,
                        'change': change
                    }
    except Exception as e:
        print(f"è·å–æŒ‡æ•°å¤±è´¥ {symbol}: {e}")
    return None


def get_sina_news():
    """
    è·å–æ–°æµªè´¢ç»æ–°é—»
    æ•°æ®æº: æ–°æµªè´¢ç»API
    """
    news_items = []
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # æ–°æµªè´¢ç»å›½é™…è´¢ç»æ–°é—»
        news_url = "https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2516&k=&num=20&r=0.5"
        response = requests.get(news_url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            if 'result' in data and 'data' in data['result']:
                for item in data['result']['data'][:15]:
                    news_items.append({
                        'title': item.get('title', ''),
                        'time': item.get('ctime', ''),
                        'source': 'æ–°æµªè´¢ç»'
                    })
    except Exception as e:
        print(f"  âš ï¸ æ–°æµªè´¢ç»è·å–å¤±è´¥: {e}")
    return news_items


def get_tencent_news():
    """
    è·å–è…¾è®¯è´¢ç»æ–°é—»
    æ•°æ®æº: è…¾è®¯è´¢ç»API / å¤‡ç”¨: Jina Readerè§£æ
    æ³¨æ„: è…¾è®¯è´¢ç»æœ‰åçˆ¬æœºåˆ¶ï¼ŒAPIç»å¸¸è¿”å›ç©ºæ•°æ®
    """
    news_items = []
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # å°è¯•å¤šç§è…¾è®¯è´¢ç»æ•°æ®æº
        urls = [
            # APIæ–¹å¼
            "https://i.news.qq.com/trpc.qqnews_web.kv_srv.kv_srv_http_proxy/list?sub_srv_id=finance&srv_id=pc&limit=10",
            "https://i.news.qq.com/trpc.qqnews_web.kv_srv.kv_srv_http_proxy/list?sub_srv_id=24hours&srv_id=pc&limit=10",
        ]
        
        for url in urls:
            try:
                response = requests.get(url, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    # è…¾è®¯APIç»å¸¸è¿”å› {"data": null}
                    if data.get('ret') == 0 and data.get('data') and 'list' in data['data']:
                        for item in data['data']['list'][:8]:
                            news_items.append({
                                'title': item.get('title', ''),
                                'time': item.get('time', ''),
                                'source': 'è…¾è®¯è´¢ç»'
                            })
            except:
                continue
                
    except Exception as e:
        print(f"  âš ï¸ è…¾è®¯è´¢ç»è·å–å¤±è´¥: {e}")
    
    # å¦‚æœAPIè·å–ä¸åˆ°ï¼Œå°è¯•å¤‡ç”¨æ–¹æ¡ˆ
    if not news_items:
        print("  âš ï¸ è…¾è®¯è´¢ç»APIè¿”å›ç©ºæ•°æ®ï¼Œå°è¯•å¤‡ç”¨æº...")
    
    return news_items


def get_wy_news():
    """
    è·å–ç½‘æ˜“è´¢ç»æ–°é—»ï¼ˆç¾è‚¡ç›¸å…³ï¼‰
    æ•°æ®æº: ç½‘æ˜“è´¢ç»
    æ³¨æ„: ç½‘æ˜“è´¢ç»é¡µé¢ç»å¸¸æ”¹ç‰ˆï¼Œéœ€å¤šå°è¯•å‡ ä¸ªé€‰æ‹©å™¨
    """
    news_items = []
    try:
        import requests
        from bs4 import BeautifulSoup
        
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # ç½‘æ˜“ç¾è‚¡æ–°é—»
        url = "https://money.163.com/stock/usstock/"
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            # æå–æ–°é—»æ ‡é¢˜ - å¤šå°è¯•å‡ ä¸ªé€‰æ‹©å™¨
            selectors = [
                '.hidden-title a', '.news_title a', '.title a',
                '.news-list h2 a', '.news-item h3 a', 'h2 a', 'h3 a'
            ]
            for selector in selectors:
                news_links = soup.select(selector)[:10]
                for link in news_links:
                    title = link.get_text().strip()
                    if title and len(title) > 5:
                        news_items.append({
                            'title': title,
                            'time': '',
                            'source': 'ç½‘æ˜“è´¢ç»'
                        })
                if news_items:
                    break
    except Exception as e:
        print(f"  âš ï¸ ç½‘æ˜“è´¢ç»è·å–å¤±è´¥: {e}")
    return news_items


def get_eastmoney_news():
    """
    è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»ï¼ˆå¤‡ç”¨æºï¼‰
    æ•°æ®æº: ä¸œæ–¹è´¢å¯ŒAPI
    """
    news_items = []
    try:
        import requests
        
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # ä¸œæ–¹è´¢å¯Œè´¢ç»è¦é—»API
        url = "https://np-anotice-stock.eastmoney.com/api/security/ann?page_size=20&page_index=1"
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data.get('data') and 'list' in data['data']:
                for item in data['data']['list'][:8]:
                    news_items.append({
                        'title': item.get('art_title', ''),
                        'time': item.get('art_time', ''),
                        'source': 'ä¸œæ–¹è´¢å¯Œ'
                    })
    except Exception as e:
        print(f"  âš ï¸ ä¸œæ–¹è´¢å¯Œè·å–å¤±è´¥: {e}")
    return news_items


def get_cls_news():
    """
    è·å–è´¢è”ç¤¾æ–°é—»ï¼ˆå¤‡ç”¨æºï¼‰
    æ•°æ®æº: è´¢è”ç¤¾RSS
    """
    news_items = []
    try:
        import feedparser
        
        # è´¢è”ç¤¾ RSS
        rss_url = "https://www.cls.cn/telegraph"
        
        # ä½¿ç”¨ feedparser è§£æ
        d = feedparser.parse(rss_url)
        for entry in d.entries[:5]:
            news_items.append({
                'title': entry.title,
                'time': '',
                'source': 'è´¢è”ç¤¾'
            })
    except Exception as e:
        print(f"  âš ï¸ è´¢è”ç¤¾è·å–å¤±è´¥: {e}")
    return news_items


def get_wallstreetcn_news():
    """
    è·å–åå°”è¡—è§é—»æ–°é—»
    æ•°æ®æº: åå°”è¡—è§é—»API
    """
    news_items = []
    try:
        import requests
        
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # åå°”è¡—è§é—»å¿«è®¯API
        url = "https://api-one.wallstcn.com/apiv1/content/information-flow?accept=article%2Cad&limit=20"
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data.get('code') == 20000 and data.get('data'):
                items = data['data'].get('items', [])
                for item in items[:10]:
                    resource = item.get('resource', {})
                    title = resource.get('title', '')
                    if title:
                        news_items.append({
                            'title': title,
                            'time': resource.get('display_time', ''),
                            'source': 'åå°”è¡—è§é—»'
                        })
    except Exception as e:
        print(f"  âš ï¸ åå°”è¡—è§é—»è·å–å¤±è´¥: {e}")
    return news_items


def get_yicai_news():
    """
    è·å–ç¬¬ä¸€è´¢ç»æ–°é—»
    æ•°æ®æº: ç¬¬ä¸€è´¢ç»API
    """
    news_items = []
    try:
        import requests
        
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # ç¬¬ä¸€è´¢ç»æ–°é—»API
        url = "https://www.yicai.com/api/ajax/getlatest?page=1&pagesize=15"
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data:
                for item in data[:10]:
                    title = item.get('NewsTitle', '')
                    if title:
                        news_items.append({
                            'title': title,
                            'time': item.get('CreateDate', ''),
                            'source': 'ç¬¬ä¸€è´¢ç»'
                        })
    except Exception as e:
        print(f"  âš ï¸ ç¬¬ä¸€è´¢ç»è·å–å¤±è´¥: {e}")
    return news_items


def get_hexun_news():
    """
    è·å–å’Œè®¯ç½‘æ–°é—»
    æ•°æ®æº: å’Œè®¯ç½‘RSS
    """
    news_items = []
    try:
        import feedparser
        
        # å’Œè®¯ç½‘è´¢ç»RSS
        rss_urls = [
            "http://rss.hexun.com/finance.xml",
            "http://rss.hexun.com/stock.xml"
        ]
        
        for rss_url in rss_urls:
            try:
                d = feedparser.parse(rss_url)
                for entry in d.entries[:5]:
                    news_items.append({
                        'title': entry.title,
                        'time': '',
                        'source': 'å’Œè®¯ç½‘'
                    })
            except:
                continue
    except Exception as e:
        print(f"  âš ï¸ å’Œè®¯ç½‘è·å–å¤±è´¥: {e}")
    return news_items


def get_ftchinese_news():
    """
    è·å–FTä¸­æ–‡ç½‘æ–°é—»
    æ•°æ®æº: FTä¸­æ–‡ç½‘RSS
    """
    news_items = []
    try:
        import feedparser
        
        # FTä¸­æ–‡ç½‘RSS
        rss_url = "https://www.ftchinese.com/rss/news"
        
        d = feedparser.parse(rss_url)
        for entry in d.entries[:8]:
            news_items.append({
                'title': entry.title,
                'time': '',
                'source': 'FTä¸­æ–‡ç½‘'
            })
    except Exception as e:
        print(f"  âš ï¸ FTä¸­æ–‡ç½‘è·å–å¤±è´¥: {e}")
    return news_items


def get_agent_reach_news():
    """
    ä½¿ç”¨ Agent Reach å·¥å…·è·å–æ–°é—»
    ä¿¡æ¯æº: æ–°æµªè´¢ç»/è…¾è®¯è´¢ç»/å›½é™…æ–°é—»ç½‘é¡µ
    """
    news_items = []
    try:
        import subprocess
        import json
        
        # ä½¿ç”¨ Agent Reach çš„ xreach æœç´¢å›½é™…è´¢ç»æ–°é—»
        keywords = ["ç¾è‚¡", "ç¾è”å‚¨", "ç§‘æŠ€è‚¡", "ä¸­æ¦‚è‚¡", "AI", "åŠå¯¼ä½“"]
        
        for keyword in keywords[:3]:  # é™åˆ¶å…³é”®è¯æ•°é‡
            try:
                # ä½¿ç”¨ curl + Jina Reader è·å–æ–°æµªè´¢ç»æ–°é—»
                url = f"https://r.jina.ai/http://finance.sina.com.cn/roll/index.d.html?keyword={keyword}"
                result = subprocess.run(
                    ['curl', '-s', '-L', '--max-time', '8', url],
                    capture_output=True, text=True, timeout=10
                )
                if result.returncode == 0 and result.stdout:
                    # è§£ææ–°é—»æ ‡é¢˜ï¼ˆç®€å•æå–ï¼‰
                    lines = result.stdout.strip().split('\n')[:5]
                    for line in lines:
                        if len(line) > 10 and '{' not in line:
                            news_items.append({
                                'title': line[:80],
                                'time': '',
                                'source': f'AgentReach-{keyword}'
                            })
            except:
                continue
        
        # ä½¿ç”¨ yt-dlp è·å– YouTube è´¢ç»è§†é¢‘æ ‡é¢˜ (å¦‚æœå¯ç”¨)
        try:
            result = subprocess.run(
                ['yt-dlp', '--flat-playlist', '--dump-json', 
                 'https://www.youtube.com/@CNBCtv/videos'],
                capture_output=True, text=True, timeout=15
            )
            if result.returncode == 0:
                videos = result.stdout.strip().split('\n')[:3]
                for video in videos:
                    try:
                        data = json.loads(video)
                        title = data.get('title', '')
                        if title and any(k in title.lower() for k in ['stock', 'market', 'trade', 'fed', 'tech']):
                            news_items.append({
                                'title': f"[YouTube] {title}",
                                'time': '',
                                'source': 'AgentReach-YouTube'
                            })
                    except:
                        continue
        except:
            pass
        
    except Exception as e:
        print(f"  âš ï¸ Agent Reach æ–°é—»è·å–å¤±è´¥: {e}")
    
    return news_items


def get_exa_news():
    """
    ä½¿ç”¨ Exa MCP è¿›è¡Œå…¨ç½‘è¯­ä¹‰æœç´¢ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
    æ•°æ®æº: Exa AI æœç´¢å¼•æ“
    """
    news_items = []
    try:
        import subprocess
        import json
        import re
        
        # ç¾è‚¡ç›¸å…³æœç´¢è¯
        search_queries = [
            "ç¾è‚¡ç§‘æŠ€è‚¡æœ€æ–°åŠ¨æ€",
            "çº³æ–¯è¾¾å…‹æŒ‡æ•°èµ°åŠ¿",
            "ç¾è”å‚¨åˆ©ç‡å†³è®®å½±å“"
        ]
        
        for query in search_queries[:2]:  # é™åˆ¶æŸ¥è¯¢æ•°é‡
            try:
                # ä½¿ç”¨ mcporter è°ƒç”¨ Exa æœç´¢
                cmd = [
                    'mcporter', 'call',
                    f'exa.web_search_exa({{"query": "{query}", "numResults": 5}})'
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
                
                if result.returncode == 0 and result.stdout:
                    # è§£ææœç´¢ç»“æœ
                    output = result.stdout
                    # æå–æ ‡é¢˜å’ŒURL
                    titles = re.findall(r'Title: (.+)', output)
                    urls = re.findall(r'URL: (.+)', output)
                    
                    for i, title in enumerate(titles[:5]):
                        if title and len(title) > 10:
                            news_items.append({
                                'title': title.strip()[:100],
                                'time': '',
                                'source': 'Exaå…¨ç½‘æœç´¢',
                                'url': urls[i] if i < len(urls) else ''
                            })
            except Exception as e:
                print(f"    Exaæœç´¢ '{query}' å¤±è´¥: {str(e)[:50]}")
                continue
                
    except Exception as e:
        print(f"  âš ï¸ Exaå…¨ç½‘æœç´¢å¤±è´¥: {e}")
    
    return news_items


def get_international_news():
    """
    è·å–å›½é™…è´¢ç»æ–°é—»ï¼ˆå¤šæºèšåˆï¼‰
    æ•°æ®æºä¼˜å…ˆçº§: Exaå…¨ç½‘æœç´¢ > æ–°æµªè´¢ç» > å…¶ä»–ä¸­æ–‡æº > Agent Reach
    """
    print("\nğŸ“° è·å–å›½é™…è´¢ç»æ–°é—»...")
    all_news = []
    
    # é«˜ä¼˜å…ˆçº§: Exaå…¨ç½‘æœç´¢
    print("  ğŸ” é«˜ä¼˜å…ˆçº§: Exaå…¨ç½‘è¯­ä¹‰æœç´¢...")
    exa_news = get_exa_news()
    all_news.extend(exa_news)
    
    # ä¸»è¦ä¸­æ–‡æ–°é—»æº
    sina_news = get_sina_news()
    wallstreetcn_news = get_wallstreetcn_news()
    yicai_news = get_yicai_news()
    eastmoney_news = get_eastmoney_news()
    
    # å¤‡ç”¨æº
    tencent_news = get_tencent_news()
    wy_news = get_wy_news()
    cls_news = get_cls_news()
    hexun_news = get_hexun_news()
    ftchinese_news = get_ftchinese_news()
    
    # Agent Reach
    agent_reach_news = get_agent_reach_news()
    
    # æŒ‰ä¼˜å…ˆçº§æ·»åŠ 
    all_news.extend(sina_news)
    all_news.extend(wallstreetcn_news)
    all_news.extend(yicai_news)
    all_news.extend(eastmoney_news)
    all_news.extend(tencent_news)
    all_news.extend(wy_news)
    all_news.extend(cls_news)
    all_news.extend(hexun_news)
    all_news.extend(ftchinese_news)
    all_news.extend(agent_reach_news)
    
    # å»é‡ï¼ˆåŸºäºæ ‡é¢˜ç›¸ä¼¼åº¦ï¼‰
    unique_news = []
    seen_titles = set()
    
    for news in all_news:
        title = news.get('title', '')
        # ç®€åŒ–æ ‡é¢˜ç”¨äºå»é‡ï¼ˆå»é™¤ç©ºæ ¼å’Œæ ‡ç‚¹ï¼‰
        simple_title = ''.join(c for c in title if c.isalnum())[:15]
        if simple_title and simple_title not in seen_titles:
            seen_titles.add(simple_title)
            unique_news.append(news)
    
    print(f"  âœ… Exaå…¨ç½‘æœç´¢: {len(exa_news)}æ¡ [é«˜ä¼˜å…ˆçº§]")
    print(f"  âœ… æ–°æµªè´¢ç»: {len(sina_news)}æ¡")
    print(f"  âœ… åå°”è¡—è§é—»: {len(wallstreetcn_news)}æ¡")
    print(f"  âœ… ç¬¬ä¸€è´¢ç»: {len(yicai_news)}æ¡")
    print(f"  âœ… ä¸œæ–¹è´¢å¯Œ: {len(eastmoney_news)}æ¡")
    print(f"  âœ… è…¾è®¯è´¢ç»: {len(tencent_news)}æ¡")
    print(f"  âœ… ç½‘æ˜“è´¢ç»: {len(wy_news)}æ¡")
    print(f"  âœ… è´¢è”ç¤¾: {len(cls_news)}æ¡")
    print(f"  âœ… å’Œè®¯ç½‘: {len(hexun_news)}æ¡")
    print(f"  âœ… FTä¸­æ–‡ç½‘: {len(ftchinese_news)}æ¡")
    print(f"  âœ… Agent Reach: {len(agent_reach_news)}æ¡")
    print(f"  âœ… å»é‡å: {len(unique_news)}æ¡")
    
    return unique_news[:30]  # è¿”å›æœ€å¤š30æ¡


def analyze_news_impact(news_items):
    """
    åˆ†ææ–°é—»å¯¹æ¿å—çš„å½±å“ï¼ˆå¢å¼ºç‰ˆï¼‰
    å…³é”®è¯æ˜ å°„åˆ°æ¿å—å½±å“ + å½±å“å¼ºåº¦è¯„ä¼°
    """
    impact_factors = []
    
    # æ‰©å±•å…³é”®è¯-æ¿å—æ˜ å°„ï¼ˆæ›´å…¨é¢çš„è´¢ç»è¯æ±‡ï¼‰
    keyword_mapping = {
        # ========== åœ°ç¼˜æ”¿æ²» -> èƒ½æº/é»„é‡‘ ==========
        'å†²çª': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'åœ°ç¼˜é£é™©æ¨å‡æ²¹ä»·', 'intensity': 3},
        'æˆ˜äº‰': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'åœ°ç¼˜é£é™©æ¨å‡æ²¹ä»·', 'intensity': 5},
        'åˆ¶è£': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'ä¾›åº”æ‹…å¿§', 'intensity': 3},
        'ä¼Šæœ—': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'ä¸­ä¸œå±€åŠ¿ç´§å¼ ', 'intensity': 4},
        'ä¸­ä¸œ': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'ä¸­ä¸œåœ°ç¼˜æ”¿æ²»', 'intensity': 3},
        'ä¿„ç½—æ–¯': {'sectors': ['èƒ½æº'], 'impact': 'å…³è”', 'reason': 'èƒ½æºä¾›åº”å½±å“', 'intensity': 2},
        'é»„é‡‘': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'é¿é™©éœ€æ±‚å‡æ¸©', 'intensity': 3},
        'é¿é™©': {'sectors': ['èƒ½æº', 'æ¶ˆè´¹'], 'impact': 'åˆ©å¥½', 'reason': 'èµ„é‡‘é¿é™©éœ€æ±‚', 'intensity': 2},
        
        # ========== AI/ç§‘æŠ€ -> AIç®—åŠ›/åŠå¯¼ä½“ ==========
        'è‹±ä¼Ÿè¾¾': {'sectors': ['AIç®—åŠ›', 'åŠå¯¼ä½“'], 'impact': 'å…³è”', 'reason': 'AIé¾™å¤´åŠ¨æ€', 'intensity': 5},
        'NVIDIA': {'sectors': ['AIç®—åŠ›', 'åŠå¯¼ä½“'], 'impact': 'å…³è”', 'reason': 'AIé¾™å¤´åŠ¨æ€', 'intensity': 5},
        'äººå·¥æ™ºèƒ½': {'sectors': ['AIç®—åŠ›'], 'impact': 'åˆ©å¥½', 'reason': 'AIäº§ä¸šæ”¿ç­–/æŠ€æœ¯çªç ´', 'intensity': 4},
        'èŠ¯ç‰‡': {'sectors': ['åŠå¯¼ä½“'], 'impact': 'å…³è”', 'reason': 'èŠ¯ç‰‡äº§ä¸šé“¾åŠ¨æ€', 'intensity': 3},
        'åŠå¯¼ä½“': {'sectors': ['åŠå¯¼ä½“'], 'impact': 'å…³è”', 'reason': 'åŠå¯¼ä½“äº§ä¸šåŠ¨æ€', 'intensity': 3},
        'ç®—åŠ›': {'sectors': ['AIç®—åŠ›'], 'impact': 'åˆ©å¥½', 'reason': 'ç®—åŠ›éœ€æ±‚å¢é•¿', 'intensity': 3},
        'æ•°æ®ä¸­å¿ƒ': {'sectors': ['å­˜å‚¨/æ•°æ®ä¸­å¿ƒ', 'AIç®—åŠ›'], 'impact': 'åˆ©å¥½', 'reason': 'æ•°æ®ä¸­å¿ƒæŠ•èµ„', 'intensity': 2},
        'äº‘è®¡ç®—': {'sectors': ['ç§‘æŠ€å·¨å¤´', 'AIç®—åŠ›'], 'impact': 'åˆ©å¥½', 'reason': 'äº‘æœåŠ¡å¢é•¿', 'intensity': 2},
        'å¤§æ¨¡å‹': {'sectors': ['AIç®—åŠ›', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'åˆ©å¥½', 'reason': 'AIå¤§æ¨¡å‹ç«èµ›', 'intensity': 3},
        
        # ========== é€šèƒ€/åˆ©ç‡ -> é‡‘è/ç§‘æŠ€ ==========
        'é€šèƒ€': {'sectors': ['é‡‘è', 'æ¶ˆè´¹'], 'impact': 'åˆ©ç©º', 'reason': 'åŠ æ¯é¢„æœŸå‡æ¸©', 'intensity': 4},
        'é€šèƒ€è¶…é¢„æœŸ': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'åˆ©ç©º', 'reason': 'ç´§ç¼©æ‹…å¿§åŠ å‰§', 'intensity': 5},
        'åˆ©ç‡': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'åˆ©ç‡æ”¿ç­–å˜åŒ–', 'intensity': 3},
        'åŠ æ¯': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´', 'AIç®—åŠ›'], 'impact': 'åˆ©ç©º', 'reason': 'èµ„é‡‘æˆæœ¬ä¸Šå‡', 'intensity': 4},
        'é™æ¯': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´', 'AIç®—åŠ›'], 'impact': 'åˆ©å¥½', 'reason': 'æµåŠ¨æ€§å®½æ¾', 'intensity': 4},
        'ç¾è”å‚¨': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'ç¾è”å‚¨æ”¿ç­–åŠ¨å‘', 'intensity': 4},
        'é²å¨å°”': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'ç¾è”å‚¨ä¸»å¸­è®²è¯', 'intensity': 3},
        'CPI': {'sectors': ['é‡‘è', 'æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'é€šèƒ€æ•°æ®å‘å¸ƒ', 'intensity': 4},
        'PPI': {'sectors': ['é‡‘è', 'æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'é€šèƒ€æ•°æ®å‘å¸ƒ', 'intensity': 3},
        'éå†œæ•°æ®': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'å°±ä¸šæ•°æ®å½±å“', 'intensity': 3},
        
        # ========== è´¸æ˜“ -> ä¸­æ¦‚äº’è”/ç§‘æŠ€ ==========
        'è´¸æ˜“': {'sectors': ['ä¸­æ¦‚äº’è”', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'å…³è”', 'reason': 'è´¸æ˜“æ”¿ç­–å˜åŒ–', 'intensity': 3},
        'å…³ç¨': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'åˆ©ç©º', 'reason': 'è´¸æ˜“æ‘©æ“¦é£é™©', 'intensity': 4},
        'ä¸­ç¾': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ä¸­ç¾å…³ç³»åŠ¨æ€', 'intensity': 3},
        'ç‰¹æœ—æ™®': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'æ”¿ç­–ä¸ç¡®å®šæ€§', 'intensity': 2},
        'è„±é’©': {'sectors': ['ä¸­æ¦‚äº’è”', 'åŠå¯¼ä½“'], 'impact': 'åˆ©ç©º', 'reason': 'ä¾›åº”é“¾é£é™©', 'intensity': 4},
        
        # ========== ç–«æƒ…/åŒ»è¯ -> ç”Ÿç‰©åŒ»è¯ ==========
        'ç–«æƒ…': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'åˆ©å¥½', 'reason': 'åŒ»è¯éœ€æ±‚å¢åŠ ', 'intensity': 3},
        'ç–«è‹—': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'åˆ©å¥½', 'reason': 'ç–«è‹—ä¼ä¸šå—ç›Š', 'intensity': 2},
        'è¯å“': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'å…³è”', 'reason': 'åŒ»è¯äº§ä¸šåŠ¨æ€', 'intensity': 2},
        'æ–°è¯': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'åˆ©å¥½', 'reason': 'æ–°è¯ç ”å‘çªç ´', 'intensity': 3},
        'å‡è‚¥è¯': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'åˆ©å¥½', 'reason': 'GLP-1è¯ç‰©çƒ­æ½®', 'intensity': 4},
        'ç¤¼æ¥': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'å…³è”', 'reason': 'åŒ»è¯é¾™å¤´åŠ¨æ€', 'intensity': 3},
        'è¯ºå’Œè¯ºå¾·': {'sectors': ['ç”Ÿç‰©åŒ»è¯'], 'impact': 'å…³è”', 'reason': 'åŒ»è¯é¾™å¤´åŠ¨æ€', 'intensity': 3},
        
        # ========== å…‰é€šè®¯/é€šä¿¡ ==========
        'å…‰æ¨¡å—': {'sectors': ['å…‰é€šè®¯'], 'impact': 'åˆ©å¥½', 'reason': 'å…‰æ¨¡å—éœ€æ±‚å¢é•¿', 'intensity': 4},
        'å…‰é€šä¿¡': {'sectors': ['å…‰é€šè®¯'], 'impact': 'å…³è”', 'reason': 'å…‰é€šè®¯äº§ä¸š', 'intensity': 3},
        '5G': {'sectors': ['å…‰é€šè®¯', 'åŠå¯¼ä½“'], 'impact': 'åˆ©å¥½', 'reason': 'é€šä¿¡åŸºå»ºæŠ•èµ„', 'intensity': 2},
        '6G': {'sectors': ['å…‰é€šè®¯', 'åŠå¯¼ä½“'], 'impact': 'åˆ©å¥½', 'reason': 'ä¸‹ä¸€ä»£é€šä¿¡æŠ€æœ¯', 'intensity': 2},
        'é€šä¿¡': {'sectors': ['å…‰é€šè®¯'], 'impact': 'å…³è”', 'reason': 'é€šä¿¡è¡Œä¸šåŠ¨æ€', 'intensity': 2},
        
        # ========== èƒ½æº ==========
        'åŸæ²¹': {'sectors': ['èƒ½æº'], 'impact': 'å…³è”', 'reason': 'åŸæ²¹ä»·æ ¼æ³¢åŠ¨', 'intensity': 4},
        'çŸ³æ²¹': {'sectors': ['èƒ½æº'], 'impact': 'å…³è”', 'reason': 'çŸ³æ²¹äº§ä¸šåŠ¨æ€', 'intensity': 3},
        'å¤©ç„¶æ°”': {'sectors': ['èƒ½æº'], 'impact': 'å…³è”', 'reason': 'å¤©ç„¶æ°”ä»·æ ¼', 'intensity': 2},
        'OPEC': {'sectors': ['èƒ½æº'], 'impact': 'å…³è”', 'reason': 'OPECæ”¿ç­–', 'intensity': 3},
        'æ–°èƒ½æº': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'èƒ½æºè½¬å‹', 'intensity': 2},
        'ç”µåŠ¨è½¦': {'sectors': ['èƒ½æº', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'å…³è”', 'reason': 'æ–°èƒ½æºæ±½è½¦', 'intensity': 2},
        'ç‰¹æ–¯æ‹‰': {'sectors': ['ç§‘æŠ€å·¨å¤´'], 'impact': 'å…³è”', 'reason': 'ç”µåŠ¨è½¦é¾™å¤´', 'intensity': 4},
        
        # ========== é‡‘è ==========
        'é“¶è¡Œ': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'é“¶è¡Œä¸šåŠ¨æ€', 'intensity': 2},
        'åå°”è¡—': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'é‡‘èä¸­å¿ƒåŠ¨æ€', 'intensity': 2},
        'è´¢æŠ¥': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'å…³è”', 'reason': 'è´¢æŠ¥å­£å½±å“', 'intensity': 3},
        'ä¸šç»©': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´', 'AIç®—åŠ›'], 'impact': 'å…³è”', 'reason': 'ä¸šç»©å‘å¸ƒ', 'intensity': 3},
        'è¶…é¢„æœŸ': {'sectors': ['ç§‘æŠ€å·¨å¤´'], 'impact': 'åˆ©å¥½', 'reason': 'ä¸šç»©è¶…é¢„æœŸ', 'intensity': 4},
        'ä¸åŠé¢„æœŸ': {'sectors': ['ç§‘æŠ€å·¨å¤´'], 'impact': 'åˆ©ç©º', 'reason': 'ä¸šç»©ä¸åŠé¢„æœŸ', 'intensity': 4},
        
        # ========== æ¶ˆè´¹ ==========
        'æ¶ˆè´¹': {'sectors': ['æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'æ¶ˆè´¹æ•°æ®', 'intensity': 2},
        'é›¶å”®': {'sectors': ['æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'é›¶å”®æ•°æ®', 'intensity': 2},
        'ç”µå•†': {'sectors': ['ä¸­æ¦‚äº’è”', 'æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'ç”µå•†åŠ¨æ€', 'intensity': 2},
        
        # ========== å­˜å‚¨ ==========
        'å­˜å‚¨': {'sectors': ['å­˜å‚¨/æ•°æ®ä¸­å¿ƒ'], 'impact': 'å…³è”', 'reason': 'å­˜å‚¨äº§ä¸š', 'intensity': 2},
        'å­˜å‚¨èŠ¯ç‰‡': {'sectors': ['å­˜å‚¨/æ•°æ®ä¸­å¿ƒ', 'åŠå¯¼ä½“'], 'impact': 'å…³è”', 'reason': 'å­˜å‚¨èŠ¯ç‰‡åŠ¨æ€', 'intensity': 3},
        'DDR': {'sectors': ['å­˜å‚¨/æ•°æ®ä¸­å¿ƒ'], 'impact': 'å…³è”', 'reason': 'å†…å­˜ä»·æ ¼', 'intensity': 2},
        
        # ========== ä¸­æ¦‚äº’è” ==========
        'é˜¿é‡Œ': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ä¸­æ¦‚é¾™å¤´åŠ¨æ€', 'intensity': 3},
        'é˜¿é‡Œå·´å·´': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ä¸­æ¦‚é¾™å¤´åŠ¨æ€', 'intensity': 3},
        'äº¬ä¸œ': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ä¸­æ¦‚ç”µå•†åŠ¨æ€', 'intensity': 2},
        'æ‹¼å¤šå¤š': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ä¸­æ¦‚ç”µå•†åŠ¨æ€', 'intensity': 2},
        'è…¾è®¯': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ä¸­æ¦‚ç§‘æŠ€åŠ¨æ€', 'intensity': 3},
        'æ¸¯è‚¡': {'sectors': ['ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'æ¸¯è‚¡å¸‚åœºè”åŠ¨', 'intensity': 2},
    }
    
    # åˆ†ææ¯æ¡æ–°é—»
    for news in news_items:
        title = news.get('title', '')
        source = news.get('source', 'æœªçŸ¥')
        matched = False
        
        # å°è¯•åŒ¹é…å…³é”®è¯ï¼ˆä¼˜å…ˆåŒ¹é…é•¿å…³é”®è¯ï¼‰
        sorted_keywords = sorted(keyword_mapping.keys(), key=len, reverse=True)
        
        for keyword in sorted_keywords:
            if keyword in title:
                mapping = keyword_mapping[keyword]
                intensity = mapping.get('intensity', 2)
                stars = "â­" * intensity + " " + ("é«˜" if intensity >= 4 else "ä¸­" if intensity >= 2 else "ä½")
                
                impact_factors.append({
                    'source': f'æ–°é—»-{source}',
                    'title': title[:40] + '...' if len(title) > 40 else title,
                    'keyword': keyword,
                    'sectors': mapping['sectors'],
                    'impact': mapping['impact'],
                    'reason': mapping['reason'],
                    'importance': stars,
                    'intensity': intensity
                })
                matched = True
                break  # æ¯æ¡æ–°é—»åªåŒ¹é…æœ€é‡è¦çš„ä¸€ä¸ªå…³é”®è¯
    
    # æŒ‰å½±å“å¼ºåº¦æ’åº
    impact_factors.sort(key=lambda x: x.get('intensity', 0), reverse=True)
    
    # å»é‡ï¼ˆåŒä¸€å…³é”®è¯çš„æ–°é—»åˆå¹¶ï¼‰
    seen_keywords = set()
    unique_factors = []
    for factor in impact_factors:
        key = factor['keyword']
        if key not in seen_keywords:
            seen_keywords.add(key)
            unique_factors.append(factor)
    
    return unique_factors[:8]  # æœ€å¤šè¿”å›8ä¸ªå› å­


def get_market_cap_data(api, symbols):
    """
    è·å–å¸‚å€¼æ•°æ®
    æ•°æ®æº: é•¿æ¡¥APIé™æ€æ•°æ® (æ€»è‚¡æœ¬Ã—å½“å‰è‚¡ä»·)
    """
    market_caps = {}
    try:
        # åˆ†æ‰¹è·å–é™æ€æ•°æ®ï¼ˆé¿å…å•æ¬¡è¯·æ±‚è¿‡å¤šï¼‰
        batch_size = 20
        for i in range(0, len(symbols), batch_size):
            batch = symbols[i:i+batch_size]
            resp = api.ctx.static_info(batch)
            for r in resp:
                symbol = str(r.symbol)
                # æ€»è‚¡æœ¬ï¼ˆè‚¡ï¼‰
                total_shares = getattr(r, 'total_shares', 0)
                market_caps[symbol] = {
                    'total_shares': total_shares,
                    'name_en': getattr(r, 'name_en', symbol),
                    'name_cn': getattr(r, 'name_cn', symbol)
                }
    except Exception as e:
        print(f"è·å–å¸‚å€¼æ•°æ®å¤±è´¥: {e}")
    return market_caps


def get_all_symbols():
    """è·å–æ‰€æœ‰éœ€è¦æŸ¥è¯¢çš„è‚¡ç¥¨ä»£ç """
    symbols = []
    for sector_data in US_SECTORS.values():
        symbols.extend(sector_data['stocks'])
    # å»é‡
    return list(set(symbols))


def analyze_sectors(quotes_dict, market_caps):
    """
    åˆ†ææ¿å—å¼ºå¼±ï¼ˆå¸‚å€¼>500äº¿ç¾å…ƒï¼‰
    è¿‡æ»¤é€»è¾‘: å¸‚å€¼ = è‚¡ä»· Ã— æ€»è‚¡æœ¬ > 500äº¿ç¾å…ƒ
    """
    sector_data = {}

    for sector_name, sector_info in US_SECTORS.items():
        stocks = []
        for symbol in sector_info['stocks']:
            if symbol in quotes_dict:
                q = quotes_dict[symbol]
                price = q.get('price', 0)

                # è®¡ç®—å¸‚å€¼ï¼ˆäº¿ç¾å…ƒï¼‰
                cap_info = market_caps.get(symbol, {})
                total_shares = cap_info.get('total_shares', 0)
                market_cap_usd = (price * total_shares) / 1e8  # è½¬æ¢ä¸ºäº¿ç¾å…ƒ

                # å¸‚å€¼è¿‡æ»¤ï¼šåªä¿ç•™ > 500äº¿ç¾å…ƒ
                if market_cap_usd >= MARKET_CAP_THRESHOLD:
                    stocks.append({
                        'symbol': symbol.replace('.US', ''),
                        'name': cap_info.get('name_cn', symbol.replace('.US', '')),
                        'name_en': cap_info.get('name_en', symbol.replace('.US', '')),
                        'price': price,
                        'change': q.get('change', 0),
                        'turnover': q.get('turnover', 0),
                        'market_cap': market_cap_usd
                    })

        if stocks:
            avg_change = sum(s['change'] for s in stocks) / len(stocks)
            up_count = sum(1 for s in stocks if s['change'] > 0)
            stocks_sorted = sorted(stocks, key=lambda x: x['change'], reverse=True)
            leader = stocks_sorted[0] if stocks_sorted else None

            sector_data[sector_name] = {
                'avg_change': avg_change,
                'up_count': up_count,
                'total': len(stocks),
                'stocks': stocks,
                'leader': leader,
                'a_share_map': sector_info['a_share_map']
            }

    # æŒ‰æ¿å—å¹³å‡æ¶¨è·Œå¹…æ’åº
    return sorted(sector_data.items(), key=lambda x: x[1]['avg_change'], reverse=True)


def identify_key_drivers(sectors, all_stocks, indices_data, news_factors):
    """
    è¯†åˆ«æ ¸å¿ƒé©±åŠ¨å› å­ï¼ˆæŠ€æœ¯é¢+æ–°é—»é¢ï¼‰
    åˆ†æç»´åº¦: æŒ‡æ•°è¡¨ç°ã€æ¿å—å¼‚åŠ¨ã€ä¸ªè‚¡æç«¯è¡Œæƒ…ã€æ–°é—»é©±åŠ¨
    """
    drivers = []

    # 1. æŒ‡æ•°å±‚é¢é©±åŠ¨
    nasdaq_change = indices_data.get('çº³æ–¯è¾¾å…‹', {}).get('change', 0)
    if abs(nasdaq_change) > 1.5:
        direction = "å¤§è·Œ" if nasdaq_change < 0 else "å¤§æ¶¨"
        drivers.append({
            'factor': f"çº³æ–¯è¾¾å…‹{direction}",
            'importance': get_importance_emoji(nasdaq_change),
            'impact': f"ç§‘æŠ€è‚¡é›†ä½“{direction[:-1]}ï¼ŒAIç®—åŠ›æ¿å—æ‰¿å‹" if nasdaq_change < 0 else "ç§‘æŠ€è‚¡å¼ºåŠ¿ï¼Œå¸¦åŠ¨å¸‚åœºæƒ…ç»ª",
            'a_share_effect': "Aè‚¡AI/åŠå¯¼ä½“æ¿å—åŒæ­¥æ‰¿å‹" if nasdaq_change < 0 else "Aè‚¡ç§‘æŠ€æ¿å—é«˜å¼€",
            'source': 'æŠ€æœ¯é¢'
        })

    # 2. æ¿å—å±‚é¢é©±åŠ¨ï¼ˆæ¶¨è·Œå¹…>3%çš„æ¿å—ï¼‰
    for sector_name, sector_info in sectors:
        avg_change = sector_info['avg_change']
        if abs(avg_change) > 3:
            direction = "å¤§è·Œ" if avg_change < 0 else "å¤§æ¶¨"
            leader = sector_info['leader']
            leader_str = f"{leader['symbol']}{format_change(leader['change'])}é¢†æ¶¨" if leader else ""

            # Aè‚¡æ˜ å°„æè¿°
            a_map = ", ".join(sector_info['a_share_map'][:3])

            drivers.append({
                'factor': f"{sector_name}{direction}",
                'importance': get_importance_emoji(avg_change),
                'impact': f"{sector_name}æ¿å—{direction}ï¼Œ{leader_str}",
                'a_share_effect': f"å…³æ³¨Aè‚¡{a_map}ç­‰æ ‡çš„",
                'source': 'æŠ€æœ¯é¢'
            })

    # 3. ä¸ªè‚¡æç«¯è¡Œæƒ…ï¼ˆæ¶¨è·Œå¹…>5%çš„å¤§å¸‚å€¼è‚¡ç¥¨ï¼‰
    large_cap_moves = [s for s in all_stocks if abs(s['change']) > 5 and s.get('market_cap', 0) > 1000]
    for stock in large_cap_moves[:3]:  # æœ€å¤šå–3ä¸ª
        direction = "æš´è·Œ" if stock['change'] < 0 else "æš´æ¶¨"
        drivers.append({
            'factor': f"{stock['symbol']}{direction}",
            'importance': get_importance_emoji(stock['change']),
            'impact': f"{stock['name']}({stock['symbol']}){format_change(stock['change'])}",
            'a_share_effect': f"{'æ‹–ç´¯' if stock['change'] < 0 else 'ææŒ¯'}åŒæ¿å—Aè‚¡æƒ…ç»ª",
            'source': 'æŠ€æœ¯é¢'
        })

    # 4. æ–°é—»é©±åŠ¨å› å­ï¼ˆä¼˜åŒ–åçš„æ ¼å¼ï¼‰
    for nf in news_factors:
        drivers.append({
            'factor': f"[æ–°é—»]{nf.get('keyword', 'é©±åŠ¨')}",
            'importance': nf.get('importance', 'â­â­ ä¸­'),
            'impact': nf['reason'],
            'a_share_effect': f"å…³æ³¨{'/'.join(nf['sectors'])}æ¿å—ï¼ˆ{nf['impact']}ï¼‰",
            'source': nf.get('source', 'æ–°é—»é¢')
        })

    return drivers


def generate_strategy(sectors, drivers, indices_data):
    """
    ç”Ÿæˆåº”å¯¹ç­–ç•¥
    ç»´åº¦: æ¿å—çº§åˆ«æ“ä½œå»ºè®®ã€ä»“ä½ç®¡ç†ã€é£é™©æç¤º
    """
    strategies = []

    for sector_name, sector_info in sectors:
        avg_change = sector_info['avg_change']
        action, advice = get_action_emoji(avg_change)

        # æ ¹æ®æ¿å—ç‰¹ç‚¹ç»†åŒ–å»ºè®®
        if sector_name == 'AIç®—åŠ›' and avg_change < -2:
            advice = "è§„é¿è¿½æ¶¨ï¼Œç­‰å¾…ä¼ç¨³ï¼Œå…³æ³¨è‹±ä¼Ÿè¾¾è´¢æŠ¥åèµ°åŠ¿"
        elif sector_name == 'åŠå¯¼ä½“' and avg_change < -1:
            advice = "çŸ­æœŸæ‰¿å‹ï¼Œå…³æ³¨å›è°ƒæœºä¼šï¼Œè®¾å¤‡è‚¡ä¼˜å…ˆ"
        elif sector_name in ['èƒ½æº', 'é»„é‡‘/æœ‰è‰²'] and avg_change > 2:
            advice = "é‡ç‚¹å…³æ³¨ï¼Œåœ°ç¼˜é£é™©+é¿é™©å±æ€§åŒå‡»"
        elif sector_name == 'ä¸­æ¦‚äº’è”' and avg_change < -2:
            advice = "æ¸¯è‚¡ç§‘æŠ€è‚¡æ‰¿å‹ï¼Œæ§åˆ¶ä»“ä½"

        strategies.append({
            'sector': sector_name,
            'action': action,
            'advice': advice,
            'a_share_map': ", ".join(sector_info['a_share_map'][:3])
        })

    return strategies


def generate_outlook(indices_data, sectors, drivers):
    """
    ç”Ÿæˆå¸‚åœºå±•æœ›
    ç»´åº¦: è¶‹åŠ¿åˆ¤æ–­ã€æ ¸å¿ƒé£é™©ã€Aè‚¡æ˜ å°„ã€æ“ä½œå»ºè®®
    """
    # è¶‹åŠ¿åˆ¤æ–­
    nasdaq = indices_data.get('çº³æ–¯è¾¾å…‹', {}).get('change', 0)
    sp500 = indices_data.get('æ ‡æ™®500', {}).get('change', 0)

    if nasdaq < -2 and sp500 < -1:
        trend = "ä¸‰å¤§æŒ‡æ•°é½è·Œï¼Œé£é™©åå¥½æ€¥å‰§æ”¶ç¼©"
        risk_level = "ğŸ”´ é«˜é£é™©"
    elif nasdaq < -1:
        trend = "ç§‘æŠ€è‚¡é¢†è·Œï¼Œä»·å€¼è‚¡ç›¸å¯¹æŠ—è·Œ"
        risk_level = "ğŸŸ  ä¸­é«˜é£é™©"
    elif nasdaq > 1 and sp500 > 0.5:
        trend = "ç§‘æŠ€è‚¡é¢†æ¶¨ï¼Œå¸‚åœºé£é™©åå¥½å›å‡"
        risk_level = "ğŸŸ¢ ä¸­ä½é£é™©"
    else:
        trend = "æŒ‡æ•°éœ‡è¡ï¼Œç­‰å¾…æ–¹å‘é€‰æ‹©"
        risk_level = "ğŸŸ¡ ä¸­æ€§"

    # æ ¸å¿ƒé£é™©
    risks = []
    if nasdaq < -1.5:
        risks.append("AI/ç§‘æŠ€è‚¡ä¼°å€¼å›è°ƒé£é™©")
    if any(s['factor'].startswith('ä¸­æ¦‚') for s in drivers):
        risks.append("ä¸­æ¦‚è‚¡æƒ…ç»ªæ³¢åŠ¨")
    if not risks:
        risks.append("åœ°ç¼˜æ”¿ç­–ä¸ç¡®å®šæ€§")

    # Aè‚¡å½±å“
    a_impact = ""
    if nasdaq < -1.5:
        a_impact = "AI/åŠå¯¼ä½“é¦–å½“å…¶å†²ï¼Œå…³æ³¨å¼€ç›˜ä½å¼€å¹…åº¦"
    elif nasdaq > 1:
        a_impact = "ç§‘æŠ€æ¿å—é«˜å¼€æ¦‚ç‡å¤§ï¼Œå…³æ³¨é‡èƒ½é…åˆ"
    else:
        a_impact = "Aè‚¡å¯èƒ½ç‹¬ç«‹èµ°åŠ¿ï¼Œå…³æ³¨å›½å†…æ”¿ç­–"

    # æ“ä½œå»ºè®®
    if nasdaq < -2:
        operation = "è§„é¿ç§‘æŠ€è¿½æ¶¨ï¼Œé…ç½®é˜²å¾¡èµ„äº§ï¼ˆé«˜è‚¡æ¯ã€é»„é‡‘ï¼‰"
    elif nasdaq < -1:
        operation = "æ§åˆ¶ä»“ä½ï¼Œç­‰å¾…ä¼ç¨³ä¿¡å·"
    elif nasdaq > 1:
        operation = "ç§¯æå‚ä¸ç§‘æŠ€ä¸»çº¿ï¼Œå…³æ³¨ä¸šç»©éªŒè¯"
    else:
        operation = "å‡è¡¡é…ç½®ï¼Œç²¾é€‰ä¸ªè‚¡"

    return {
        'trend': trend,
        'risk_level': risk_level,
        'risks': risks,
        'a_impact': a_impact,
        'operation': operation
    }


def generate_report():
    """ç”Ÿæˆç¾è‚¡æ·±åº¦åˆ†ææŠ¥å‘Š"""
    print("ğŸŒ™ æ­£åœ¨è·å–ç¾è‚¡è¡Œæƒ…æ•°æ®...")
    print("=" * 60)
    print("ğŸ“Š æ•°æ®æº: é•¿æ¡¥API (ä¸ªè‚¡è¡Œæƒ…+é™æ€æ•°æ®) + è…¾è®¯è´¢ç»API (æŒ‡æ•°)")
    print("ğŸ’° å¸‚å€¼è¿‡æ»¤: >500äº¿ç¾å…ƒ")
    print("=" * 60)

    api = get_longbridge_api()

    # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
    symbols = get_all_symbols()
    print(f"ğŸ“‹ å…± {len(symbols)} åªå…³æ³¨è‚¡ç¥¨")

    # 1. è·å–è¡Œæƒ…æ•°æ®
    print("\nğŸ“ˆ è·å–ä¸ªè‚¡è¡Œæƒ…...")
    quotes = api.get_quotes(symbols)
    if not quotes:
        print("âŒ è·å–è¡Œæƒ…æ•°æ®å¤±è´¥")
        return None
    quotes_dict = {q['symbol']: q for q in quotes}
    print(f"âœ… è·å–åˆ° {len(quotes)} åªè‚¡ç¥¨è¡Œæƒ…")

    # 2. è·å–å¸‚å€¼æ•°æ®
    print("\nğŸ’° è·å–å¸‚å€¼æ•°æ®...")
    market_caps = get_market_cap_data(api, symbols)
    print(f"âœ… è·å–åˆ° {len(market_caps)} åªè‚¡ç¥¨å¸‚å€¼")

    # 3. è·å–æŒ‡æ•°æ•°æ®
    print("\nğŸ“Š è·å–ä¸»è¦æŒ‡æ•°...")
    indices_data = {}
    for symbol, info in INDICES.items():
        idx = get_us_index_quote(symbol)
        if idx:
            indices_data[info['name']] = idx
            print(f"  âœ… {info['name']}: {format_change(idx['change'])}")

    # 4. è·å–å›½é™…æ–°é—»ï¼ˆå¤šæºï¼‰
    print("\nğŸ“° è·å–å›½é™…è´¢ç»æ–°é—»ï¼ˆå¤šæºèšåˆï¼‰...")
    news_items = get_international_news()
    news_factors = analyze_news_impact(news_items)
    print(f"âœ… è¯†åˆ« {len(news_factors)} ä¸ªæ–°é—»é©±åŠ¨å› å­")
    for nf in news_factors[:3]:
        print(f"  ğŸ“° [{nf.get('keyword', '')}] {nf.get('importance', '')} -> {'/'.join(nf.get('sectors', []))}")

    # è·å–å½“å‰æ—¥æœŸ
    now = datetime.now()
    today = now.strftime('%Y-%m-%d')
    data_date = (now - timedelta(days=1)).strftime('%Y-%m-%d')

    # 4. åˆ†ææ¿å—ï¼ˆå¸‚å€¼è¿‡æ»¤åï¼‰
    print("\nğŸ” åˆ†ææ¿å—å¼ºå¼±ï¼ˆå¸‚å€¼>500äº¿ï¼‰...")
    sectors = analyze_sectors(quotes_dict, market_caps)
    print(f"âœ… åˆ†æå®Œæˆï¼Œå…± {len(sectors)} ä¸ªæ¿å—")

    # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨ï¼ˆå·²è¿‡æ»¤ï¼‰
    all_stocks = []
    for sector_name, sector_info in sectors:
        for stock in sector_info['stocks']:
            all_stocks.append({**stock, 'sector': sector_name})
        print(f"  {sector_name}: {len(sector_info['stocks'])}åªè‚¡, å¹³å‡{format_change(sector_info['avg_change'])}")

    # 5. äº®ç‚¹/æ‹–ç´¯ä¸ªè‚¡ï¼ˆå·²è¿‡æ»¤å¤§å¸‚å€¼ï¼‰
    top_gainers = sorted(all_stocks, key=lambda x: x['change'], reverse=True)[:5]
    top_losers = sorted(all_stocks, key=lambda x: x['change'])[:5]

    # 6. è¯†åˆ«æ ¸å¿ƒé©±åŠ¨ï¼ˆæŠ€æœ¯é¢+æ–°é—»é¢ï¼‰
    print("\nğŸ” è¯†åˆ«æ ¸å¿ƒé©±åŠ¨å› å­...")
    drivers = identify_key_drivers(sectors, all_stocks, indices_data, news_factors)
    print(f"âœ… è¯†åˆ« {len(drivers)} ä¸ªé©±åŠ¨å› å­")

    # 7. ç”Ÿæˆç­–ç•¥
    strategies = generate_strategy(sectors, drivers, indices_data)

    # 8. ç”Ÿæˆå±•æœ›
    outlook = generate_outlook(indices_data, sectors, drivers)

    # ===== ç”ŸæˆæŠ¥å‘Š =====
    report_lines = [
        f"# ğŸ“Š ç¾è‚¡å¸‚åœºæ·±åº¦åˆ†ææŠ¥å‘Š",
        f"",
        f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {now.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**æ•°æ®æ—¥æœŸ**: {data_date}ï¼ˆå‰ä¸€äº¤æ˜“æ—¥ï¼‰",
        f"**åˆ†æèŒƒå›´**: å¸‚å€¼>500äº¿ç¾å…ƒç¾è‚¡",
        f"",
        f"---",
        f"",
        f"## ä¸€ã€ä¸»è¦æŒ‡æ•°è¡¨ç°",
        f"",
        f"| æŒ‡æ•° | æ¶¨è·Œå¹… | æ•°æ®æº |",
        f"|------|--------|--------|"
    ]

    for name, idx in indices_data.items():
        source = INDICES.get(f"us{name}", {}).get('source', 'è…¾è®¯è´¢ç»API')
        report_lines.append(f"| {get_emoji(idx['change'])} **{name}** | {format_change(idx['change'])} | {source} |")

    report_lines.extend([
        f"",
        f"**è¶‹åŠ¿åˆ¤æ–­**: {outlook['trend']}",
        f"**é£é™©ç­‰çº§**: {outlook['risk_level']}",
        f"",
        f"---",
        f"",
        f"## äºŒã€æ¿å—å¼ºå¼±æ’åºï¼ˆå¸‚å€¼>500äº¿ï¼‰",
        f"",
        f"| æ’å | æ¿å— | å¹³å‡æ¶¨è·Œ | ä¸ªè‚¡æ•° | é¢†æ¶¨è‚¡ | Aè‚¡æ˜ å°„ |",
        f"|------|------|----------|--------|--------|----------|"
    ])

    for i, (sector_name, sector_info) in enumerate(sectors, 1):
        emoji = get_emoji(sector_info['avg_change'])
        rank = get_rank_emoji(i)
        leader = sector_info['leader']
        leader_str = f"{leader['symbol']} {format_change(leader['change'])}" if leader else "-"
        a_map = ", ".join(sector_info['a_share_map'][:2])

        report_lines.append(
            f"| {rank} | {emoji} {sector_name} | {format_change(sector_info['avg_change'])} | {sector_info['total']}åª | {leader_str} | {a_map} |"
        )

    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## ä¸‰ã€æ ¸å¿ƒé©±åŠ¨å› å­ï¼ˆç¾è‚¡â†’Aè‚¡ä¼ å¯¼ï¼‰",
        f"",
        f"*é©±åŠ¨å› å­æ¥æº: æŠ€æœ¯é¢ï¼ˆè¡Œæƒ…æ•°æ®ï¼‰+ æ–°é—»é¢ï¼ˆè´¢ç»æ–°é—»åˆ†æï¼‰*",
        f"",
        f"| é©±åŠ¨å› å­ | é‡è¦åº¦ | ç¾è‚¡ç°è±¡ | Aè‚¡å½±å“ | æ¥æº |",
        f"|----------|--------|----------|----------|------|"
    ])

    for driver in drivers[:8]:  # æœ€å¤šæ˜¾ç¤º8ä¸ª
        source = driver.get('source', 'æŠ€æœ¯é¢')
        report_lines.append(
            f"| {driver['factor']} | {driver['importance']} | {driver['impact']} | {driver['a_share_effect']} | {source} |"
        )

    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## å››ã€åº”å¯¹ç­–ç•¥",
        f"",
        f"| æ¿å— | æ“ä½œ | å»ºè®® | Aè‚¡å…³æ³¨æ ‡çš„ |",
        f"|------|------|------|-------------|"
    ])

    for strategy in strategies:
        report_lines.append(
            f"| {strategy['sector']} | {strategy['action']} | {strategy['advice']} | {strategy['a_share_map']} |"
        )

    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## äº”ã€é‡ç‚¹ä¸ªè‚¡ï¼ˆå¸‚å€¼>500äº¿ï¼‰",
        f"",
        f"### ğŸ”¥ äº®ç‚¹ä¸ªè‚¡",
        f"",
        f"| è‚¡ç¥¨ | æ¶¨è·Œå¹… | å¸‚å€¼ | æ¿å— |",
        f"|------|--------|------|------|"
    ])

    for stock in top_gainers:
        emoji = "ğŸš€" if stock['change'] > 5 else "ğŸ“ˆ"
        report_lines.append(
            f"| {emoji} {stock['symbol']} | {format_change(stock['change'])} | {stock['market_cap']:.0f}äº¿ | {stock['sector']} |"
        )

    report_lines.extend([
        f"",
        f"### ğŸ”» æ‹–ç´¯å› ç´ ",
        f"",
        f"| è‚¡ç¥¨ | æ¶¨è·Œå¹… | å¸‚å€¼ | æ¿å— |",
        f"|------|--------|------|------|"
    ])

    for stock in top_losers:
        emoji = "ğŸ”»" if stock['change'] < -5 else "ğŸ“‰"
        report_lines.append(
            f"| {emoji} {stock['symbol']} | {format_change(stock['change'])} | {stock['market_cap']:.0f}äº¿ | {stock['sector']} |"
        )

    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## å…­ã€å¸‚åœºå±•æœ›ä¸æ€»ç»“",
        f"",
        f"| ç»´åº¦ | ç»“è®º |",
        f"|------|------|",
        f"| **ç¾è‚¡è¶‹åŠ¿** | {outlook['trend']} |",
        f"| **é£é™©ç­‰çº§** | {outlook['risk_level']} |",
        f"| **Aè‚¡å½±å“** | {outlook['a_impact']} |",
        f"| **æ“ä½œå»ºè®®** | {outlook['operation']} |",
        f"",
        f"**æ ¸å¿ƒé£é™©**: {', '.join(outlook['risks'])}",
        f"",
        f"---",
        f"",
        f"## ğŸ“Œ æ•°æ®æ¥æº",
        f"",
        f"### è¡Œæƒ…æ•°æ®",
        f"- **ä¸ªè‚¡å®æ—¶è¡Œæƒ…**: é•¿æ¡¥API (Longbridge OpenAPI) - `QuoteContext.quote()`",
        f"- **ä¸ªè‚¡å¸‚å€¼**: é•¿æ¡¥APIé™æ€æ•°æ® - `QuoteContext.static_info()` (æ€»è‚¡æœ¬Ã—å½“å‰è‚¡ä»·)",
        f"- **ç¾è‚¡æŒ‡æ•°**: è…¾è®¯è´¢ç»API (https://qt.gtimg.cn)",
        f"- **æ¶¨è·Œå¹…è®¡ç®—**: (ç°ä»·-æ˜¨æ”¶)/æ˜¨æ”¶ Ã— 100%",
        f"",
        f"### æ–°é—»æ•°æ®ï¼ˆå¤šæºèšåˆï¼‰",
        f"- **æ–°æµªè´¢ç»API**: https://feed.mix.sina.com.cn/api/roll/get",
        f"- **è…¾è®¯è´¢ç»API**: https://i.news.qq.com/trpc.qqnews_web.kv_srv.kv_srv_http_proxy/list",
        f"- **ç½‘æ˜“è´¢ç»**: https://money.163.com/stock/usstock/",
        f"- **æ–°é—»åˆ†æ**: å…³é”®è¯åŒ¹é…ï¼ˆ70+å…³é”®è¯ï¼‰+ æ¿å—æ˜ å°„ + å½±å“å¼ºåº¦è¯„ä¼°",
        f"",
        f"### æ˜ å°„å…³ç³»",
        f"- **Aè‚¡æ˜ å°„**: åŸºäºä¸šåŠ¡å…³è”æ€§äººå·¥æ¢³ç†",
        f"",
        f"---",
        f"",
        f"âš ï¸ **é£é™©æç¤º**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚è‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚",
        f"- æ•°æ®å¯èƒ½å­˜åœ¨å»¶è¿Ÿï¼ˆT-1æ—¥æ•°æ®ï¼‰",
        f"- å¸‚å€¼æ•°æ®åŸºäºä¸Šä¸€äº¤æ˜“æ—¥æ”¶ç›˜ä»·è®¡ç®—",
        f"- Aè‚¡æ˜ å°„å…³ç³»åŸºäºä¸šåŠ¡å…³è”æ€§ï¼Œå¯èƒ½å­˜åœ¨åå·®",
        f"- æ–°é—»åˆ†æåŸºäºå…³é”®è¯åŒ¹é…ï¼Œå¯èƒ½é—æ¼æˆ–è¯¯åˆ¤",
        f"",
        f"ğŸ“… **ä¸‹æ¬¡ä»»åŠ¡**: 09:15 A+Hå¸‚åœºç›˜å‰åˆ†æ"
    ])

    report = "\n".join(report_lines)

    # ä¿å­˜æŠ¥å‘Š
    report_file = f"/root/.openclaw/workspace/data/us_market_daily_{now.strftime('%Y%m%d')}.md"
    os.makedirs(os.path.dirname(report_file), exist_ok=True)
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    print("\n" + "=" * 60)
    print(report[:1500])  # æ‰“å°å‰1500å­—ç¬¦é¢„è§ˆ
    print("\n... [æŠ¥å‘Šå·²æˆªæ–­] ...")

    # å‘é€åˆ°é£ä¹¦
    print("\nğŸ“¤ æ­£åœ¨å‘é€åˆ°é£ä¹¦...")
    send_feishu_message(report, "ğŸ“Š ç¾è‚¡å¸‚åœºæ·±åº¦åˆ†ææŠ¥å‘Š")

    # è®°å½•æ—¥å¿—
    with open('/root/.openclaw/workspace/tools/us_market_send.log', 'a') as f:
        f.write(f"{now}: v2.0æŠ¥å‘Šç”Ÿæˆå¹¶å‘é€\n")

    return report


if __name__ == "__main__":
    generate_report()
