#!/usr/bin/env python3
"""
A+Hè‚¡å¼€ç›˜å‰ç»æŠ¥å‘Šç”Ÿæˆå™¨ v2.0 (æ·±åº¦ç‰ˆ)
æ¯æ—¥9:15å‰ç”Ÿæˆå¼€ç›˜ç­–ç•¥åˆ†æï¼Œç»“åˆç¾è‚¡æŠ¥å‘Š+Aè‚¡/æ¸¯è‚¡æ¿å—åˆ†æ+æ–°é—»é©±åŠ¨

åˆ†ææ¡†æ¶ï¼š
1. éš”å¤œç¾è‚¡å›é¡¾ï¼ˆå¼•ç”¨ç¾è‚¡æŠ¥å‘Šæ ¸å¿ƒç»“è®ºï¼‰
2. Aè‚¡æ¿å—åˆ†æï¼ˆå¸‚å€¼>100äº¿ï¼Œå®æ—¶è¡Œæƒ…ï¼‰
3. æ¸¯è‚¡æ¿å—åˆ†æï¼ˆå¸‚å€¼>100äº¿æ¸¯å¸ï¼Œå®æ—¶è¡Œæƒ…ï¼‰
4. é›†åˆç«ä»·æ•°æ®ï¼ˆå¼€ç›˜å‰15åˆ†é’Ÿï¼‰
5. æ ¸å¿ƒé©±åŠ¨å› å­ï¼ˆæŠ€æœ¯é¢+æ–°é—»é¢ï¼‰
6. å¼€ç›˜ç­–ç•¥å»ºè®®
7. é‡ç‚¹ä¸ªè‚¡ç›‘æ§

æ•°æ®æºï¼š
- ä¸ªè‚¡è¡Œæƒ…: é•¿æ¡¥API
- ç¾è‚¡å›é¡¾: å¼•ç”¨ç¾è‚¡æŠ¥å‘Š
- æ–°é—»é©±åŠ¨: æ–°æµªè´¢ç»+è…¾è®¯+ç½‘æ˜“
- é›†åˆç«ä»·: é•¿æ¡¥APIï¼ˆå¦‚æ”¯æŒï¼‰

ä½œè€…: è±†å¥¶æŠ•èµ„ç­–ç•¥ç³»ç»Ÿ
ç‰ˆæœ¬: 2.0
"""
import sys
import os
import json
from datetime import datetime, timedelta

# åŠ è½½ç¯å¢ƒå˜é‡
env_file = '/root/.openclaw/workspace/.longbridge.env'
if os.path.exists(env_file):
    with open(env_file, 'r') as f:
        for line in f:
            if '=' in line and not line.startswith('#'):
                key, value = line.strip().split('=', 1)
                os.environ[key] = value.strip('"')

# æ·»åŠ è·¯å¾„
sys.path.insert(0, '/root/.openclaw/workspace/tools')
from longbridge_api import get_longbridge_api

# ============================================
# é…ç½®
# ============================================

USER_ID = 'ou_efbad805767f4572e8f93ebafa8d5402'

# Aè‚¡å¸‚å€¼è¿‡æ»¤ï¼ˆäº¿äººæ°‘å¸ï¼‰
A_MARKET_CAP_THRESHOLD = 100
# æ¸¯è‚¡å¸‚å€¼è¿‡æ»¤ï¼ˆäº¿æ¸¯å¸ï¼‰
H_MARKET_CAP_THRESHOLD = 100

# Aè‚¡æ¿å—å®šä¹‰ï¼ˆå¸‚å€¼>100äº¿ï¼‰
A_SECTORS = {
    'AIç®—åŠ›': {
        'stocks': ['002371.SZ', '688012.SH', '688256.SH', '300474.SZ'],
        'leaders': ['åŒ—æ–¹ååˆ›', 'ä¸­å¾®å…¬å¸', 'å¯’æ­¦çºª', 'æ™¯å˜‰å¾®'],
    },
    'åŠå¯¼ä½“è®¾å¤‡': {
        'stocks': ['688012.SH', '688072.SH', '688120.SH', '300316.SZ'],
        'leaders': ['ä¸­å¾®å…¬å¸', 'æ‹“è†ç§‘æŠ€', 'åæµ·æ¸…ç§‘', 'æ™¶ç››æœºç”µ'],
    },
    'å…‰é€šè®¯': {
        'stocks': ['300308.SZ', '300502.SZ', '300394.SZ', '002281.SZ'],
        'leaders': ['ä¸­é™…æ—­åˆ›', 'æ–°æ˜“ç››', 'å¤©å­šé€šä¿¡', 'å…‰è¿…ç§‘æŠ€'],
    },
    'æ–°èƒ½æº': {
        'stocks': ['300750.SZ', '002594.SZ', '601012.SH', '600438.SH'],
        'leaders': ['å®å¾·æ—¶ä»£', 'æ¯”äºšè¿ª', 'éš†åŸºç»¿èƒ½', 'é€šå¨è‚¡ä»½'],
    },
    'æ¶ˆè´¹': {
        'stocks': ['600519.SH', '000858.SZ', '000568.SZ', '002304.SZ'],
        'leaders': ['è´µå·èŒ…å°', 'äº”ç²®æ¶²', 'æ³¸å·è€çª–', 'æ´‹æ²³è‚¡ä»½'],
    },
    'é‡‘è': {
        'stocks': ['600036.SH', '601318.SH', '300059.SZ', '600030.SH'],
        'leaders': ['æ‹›å•†é“¶è¡Œ', 'ä¸­å›½å¹³å®‰', 'ä¸œæ–¹è´¢å¯Œ', 'ä¸­ä¿¡è¯åˆ¸'],
    },
    'åŒ»è¯': {
        'stocks': ['600276.SH', '300760.SZ', '603259.SH', '688235.SH'],
        'leaders': ['æ’ç‘åŒ»è¯', 'è¿ˆç‘åŒ»ç–—', 'è¯æ˜åº·å¾·', 'ç™¾æµç¥å·'],
    },
}

# æ¸¯è‚¡æ¿å—å®šä¹‰ï¼ˆå¸‚å€¼>100äº¿æ¸¯å¸ï¼‰
H_SECTORS = {
    'ç§‘æŠ€å·¨å¤´': {
        'stocks': ['00700.HK', '09988.HK', '03690.HK', '01810.HK'],
        'leaders': ['è…¾è®¯', 'é˜¿é‡Œ', 'ç¾å›¢', 'å°ç±³'],
    },
    'ä¸­æ¦‚äº’è”': {
        'stocks': ['09988.HK', '09618.HK', '01024.HK', '02015.HK'],
        'leaders': ['é˜¿é‡Œ', 'äº¬ä¸œ', 'å¿«æ‰‹', 'ç†æƒ³æ±½è½¦'],
    },
    'èƒ½æº': {
        'stocks': ['00883.HK', '00857.HK', '00386.HK', '01088.HK'],
        'leaders': ['ä¸­æµ·æ²¹', 'ä¸­çŸ³æ²¹', 'ä¸­çŸ³åŒ–', 'ç¥å'],
    },
    'é‡‘è': {
        'stocks': ['02318.HK', '03968.HK', '01299.HK', '01398.HK'],
        'leaders': ['å¹³å®‰', 'æ‹›è¡Œ', 'å‹é‚¦', 'å·¥è¡Œ'],
    },
    'æ¶ˆè´¹': {
        'stocks': ['01898.HK', '02331.HK', '09633.HK', '06186.HK'],
        'leaders': ['ä¸­çƒŸ', 'æå®', 'å†œå¤«å±±æ³‰', 'ä¸­å›½é£é¹¤'],
    },
    'ç”Ÿç‰©åŒ»è¯': {
        'stocks': ['02359.HK', '01801.HK', '06160.HK', '01167.HK'],
        'leaders': ['è¯æ˜åº·å¾·', 'ä¿¡è¾¾ç”Ÿç‰©', 'ç™¾æµç¥å·', 'å¤æ˜ŸåŒ»è¯'],
    },
}

# ============================================
# å·¥å…·å‡½æ•°
# ============================================

def format_change(value):
    """æ ¼å¼åŒ–æ¶¨è·Œå¹…"""
    try:
        change = float(value)
        return f"+{change:.2f}%" if change > 0 else f"{change:.2f}%"
    except:
        return "--"


def get_emoji(change):
    """æ ¹æ®æ¶¨è·Œå¹…è¿”å›è¡¨æƒ…"""
    try:
        c = float(change)
        if c > 2:
            return "ğŸš€"
        elif c > 0:
            return "ğŸ“ˆ"
        elif c > -2:
            return "ğŸ“‰"
        else:
            return "ğŸ”»"
    except:
        return "âšª"


def get_importance_emoji(change):
    """é‡è¦åº¦è¯„çº§"""
    try:
        c = abs(float(change))
        if c > 3:
            return "â­â­â­ é«˜"
        elif c > 1.5:
            return "â­â­ ä¸­"
        else:
            return "â­ ä½"
    except:
        return "-"


def get_action_emoji(change):
    """æ“ä½œå»ºè®®è¡¨æƒ…"""
    try:
        c = float(change)
        if c > 2:
            return "âœ… å…³æ³¨", "å¼ºåŠ¿ï¼Œå¯å‚ä¸"
        elif c > 0:
            return "â¡ï¸ æŒæœ‰", "å¹³ç¨³ï¼Œç»´æŒ"
        elif c > -2:
            return "âš ï¸ è§‚æœ›", "è°ƒæ•´ï¼Œç­‰å¾…"
        else:
            return "âŒ è§„é¿", "å¼±åŠ¿ï¼Œå›é¿"
    except:
        return "-", "-"


def send_feishu_message(content: str, title: str = "A+Hå¼€ç›˜æŠ¥å‘Š"):
    """å‘é€é£ä¹¦æ¶ˆæ¯"""
    try:
        import subprocess
        result = subprocess.run([
            'openclaw', 'message', 'send',
            '--channel', 'feishu',
            '--target', USER_ID,
            '--message', content
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… é£ä¹¦æ¶ˆæ¯å·²å‘é€")
            return True
        else:
            print(f"âš ï¸ é£ä¹¦å‘é€å¤±è´¥: {result.stderr[:200]}")
            return False
    except Exception as e:
        print(f"âš ï¸ é£ä¹¦å‘é€å¼‚å¸¸: {e}")
        return False


# ============================================
# æ–°é—»è·å–æ¨¡å—ï¼ˆå¤ç”¨ç¾è‚¡æŠ¥å‘Šçš„å¢å¼ºç‰ˆï¼‰
# ============================================

def get_sina_news():
    """è·å–æ–°æµªè´¢ç»æ–°é—»"""
    news_items = []
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        urls = [
            "https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2516&num=15",
            "https://feed.mix.sina.com.cn/api/roll/get?pageid=153&lid=2517&num=10",  # å›½é™…è´¢ç»
        ]
        
        for url in urls:
            try:
                response = requests.get(url, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    if 'result' in data and 'data' in data['result']:
                        for item in data['result']['data']:
                            news_items.append({
                                'title': item.get('title', ''),
                                'time': item.get('ctime', ''),
                                'source': 'æ–°æµªè´¢ç»'
                            })
            except:
                continue
    except Exception as e:
        print(f"  âš ï¸ æ–°æµªè´¢ç»: {e}")
    return news_items


def get_tencent_news():
    """è·å–è…¾è®¯è´¢ç»æ–°é—»"""
    news_items = []
    try:
        import requests
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'https://news.qq.com/'
        }
        
        # è…¾è®¯è´¢ç»API - ä½¿ç”¨æ–°çš„æ¥å£
        url = "https://i.news.qq.com/trpc.qqnews_web.kv_srv.kv_srv_http_proxy/list"
        params = {
            'sub_srv_id': 'finance',
            'srv_id': 'pc',
            'limit': 20,
            'page': 1
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data.get('ret') == 0 and 'data' in data:
                for item in data['data'].get('list', []):
                    news_items.append({
                        'title': item.get('title', ''),
                        'time': item.get('time', ''),
                        'source': 'è…¾è®¯è´¢ç»'
                    })
    except Exception as e:
        print(f"  âš ï¸ è…¾è®¯è´¢ç»: {e}")
    return news_items


def get_netease_news():
    """è·å–ç½‘æ˜“è´¢ç»æ–°é—»ï¼ˆä½¿ç”¨BeautifulSoupï¼‰"""
    news_items = []
    try:
        import requests
        from bs4 import BeautifulSoup
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        # ç½‘æ˜“ç¾è‚¡æ–°é—»
        url = "https://money.163.com/stock/usstock/"
        response = requests.get(url, headers=headers, timeout=15)
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'lxml')
            
            # æå–æ–°é—»æ ‡é¢˜ - é€‚é…ç½‘æ˜“è´¢ç»é¡µé¢ç»“æ„
            selectors = [
                '.news_title a', '.title a', '.hidden-title a',
                '.news_list h2 a', '.item a', '.item-txt a'
            ]
            
            for selector in selectors:
                links = soup.select(selector)[:10]
                for link in links:
                    title = link.get_text().strip()
                    if title and len(title) > 5:
                        news_items.append({
                            'title': title,
                            'time': '',
                            'source': 'ç½‘æ˜“è´¢ç»'
                        })
                if news_items:
                    break
                    
    except Exception as e:
        print(f"  âš ï¸ ç½‘æ˜“è´¢ç»: {e}")
    return news_items


def get_agent_reach_news():
    """ä½¿ç”¨ Agent Reach å·¥å…·è·å–æ–°é—»"""
    news_items = []
    try:
        import subprocess
        import json
        
        # ä½¿ç”¨ yt-dlp è·å– YouTube è´¢ç»è§†é¢‘ä¿¡æ¯ (å¦‚æœå¯ç”¨)
        try:
            result = subprocess.run(
                ['yt-dlp', '--flat-playlist', '--dump-json', 
                 '--playlist-end', '5',
                 'https://www.youtube.com/@CNBCtv/videos'],
                capture_output=True, text=True, timeout=15
            )
            if result.returncode == 0:
                videos = result.stdout.strip().split('\n')
                for video in videos[:3]:
                    try:
                        if video:
                            data = json.loads(video)
                            title = data.get('title', '')
                            if title and any(k in title.lower() for k in ['stock', 'market', 'trade', 'fed', 'tech', 'china']):
                                news_items.append({
                                    'title': f"[YouTube] {title}",
                                    'time': '',
                                    'source': 'AgentReach-YouTube'
                                })
                    except:
                        continue
        except:
            pass
        
        # ä½¿ç”¨ feedparser è¯»å– RSS
        try:
            import feedparser
            rss_urls = [
                'https://feeds.a.dj.com/rss/RSSMarketsMain.xml',
                'https://feeds.a.dj.com/rss/RSSWorldNews.xml'
            ]
            for url in rss_urls:
                try:
                    d = feedparser.parse(url)
                    for entry in d.entries[:3]:
                        news_items.append({
                            'title': f"[RSS] {entry.title}",
                            'time': '',
                            'source': 'AgentReach-RSS'
                        })
                except:
                    continue
        except:
            pass
        
    except Exception as e:
        print(f"  âš ï¸ Agent Reach: {e}")
    
    return news_items


def get_wallstreetcn_news():
    """è·å–åå°”è¡—è§é—»æ–°é—»"""
    news_items = []
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        url = "https://api-one.wallstcn.com/apiv1/content/information-flow?accept=article%2Cad&limit=10"
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data.get('code') == 20000 and data.get('data'):
                items = data['data'].get('items', [])
                for item in items[:8]:
                    resource = item.get('resource', {})
                    title = resource.get('title', '')
                    if title:
                        news_items.append({
                            'title': title,
                            'time': resource.get('display_time', ''),
                            'source': 'åå°”è¡—è§é—»'
                        })
    except Exception as e:
        print(f"  âš ï¸ åå°”è¡—è§é—»: {e}")
    return news_items


def get_yicai_news():
    """è·å–ç¬¬ä¸€è´¢ç»æ–°é—»"""
    news_items = []
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        url = "https://www.yicai.com/api/ajax/getlatest?page=1&pagesize=10"
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data:
                for item in data[:8]:
                    title = item.get('NewsTitle', '')
                    if title:
                        news_items.append({
                            'title': title,
                            'time': item.get('CreateDate', ''),
                            'source': 'ç¬¬ä¸€è´¢ç»'
                        })
    except Exception as e:
        print(f"  âš ï¸ ç¬¬ä¸€è´¢ç»: {e}")
    return news_items


def get_eastmoney_news():
    """è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»"""
    news_items = []
    try:
        import requests
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        url = "https://np-anotice-stock.eastmoney.com/api/security/ann?page_size=10&page_index=1"
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if data.get('data') and 'list' in data['data']:
                for item in data['data']['list'][:8]:
                    news_items.append({
                        'title': item.get('art_title', ''),
                        'time': item.get('art_time', ''),
                        'source': 'ä¸œæ–¹è´¢å¯Œ'
                    })
    except Exception as e:
        print(f"  âš ï¸ ä¸œæ–¹è´¢å¯Œ: {e}")
    return news_items


def get_exa_news():
    """
    ä½¿ç”¨ Exa MCP è¿›è¡Œå…¨ç½‘è¯­ä¹‰æœç´¢ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
    æ•°æ®æº: Exa AI æœç´¢å¼•æ“
    """
    news_items = []
    try:
        import subprocess
        import re
        
        # A+Hç›¸å…³æœç´¢è¯
        search_queries = [
            "Aè‚¡æ¸¯è‚¡æœ€æ–°åŠ¨æ€",
            "ä¸­å›½è‚¡å¸‚æ”¿ç­–",
            "æ¸¯è‚¡ç§‘æŠ€è‚¡èµ°åŠ¿"
        ]
        
        for query in search_queries[:2]:
            try:
                cmd = [
                    'mcporter', 'call',
                    f'exa.web_search_exa({{"query": "{query}", "numResults": 5}})'
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
                
                if result.returncode == 0 and result.stdout:
                    output = result.stdout
                    titles = re.findall(r'Title: (.+)', output)
                    urls = re.findall(r'URL: (.+)', output)
                    
                    for i, title in enumerate(titles[:5]):
                        if title and len(title) > 10:
                            news_items.append({
                                'title': title.strip()[:100],
                                'time': '',
                                'source': 'Exaå…¨ç½‘æœç´¢',
                                'url': urls[i] if i < len(urls) else ''
                            })
            except:
                continue
                
    except Exception as e:
        print(f"  âš ï¸ Exaå…¨ç½‘æœç´¢: {e}")
    
    return news_items


def get_international_news():
    """è·å–å›½é™…è´¢ç»æ–°é—»ï¼ˆå¤šæºèšåˆï¼‰"""
    print("\nğŸ“° è·å–è´¢ç»æ–°é—»ï¼ˆå¤šæºèšåˆï¼‰...")
    all_news = []
    
    # é«˜ä¼˜å…ˆçº§: Exaå…¨ç½‘æœç´¢
    print("  ğŸ” é«˜ä¼˜å…ˆçº§: Exaå…¨ç½‘è¯­ä¹‰æœç´¢...")
    exa_news = get_exa_news()
    all_news.extend(exa_news)
    
    sina_news = get_sina_news()
    tencent_news = get_tencent_news()
    netease_news = get_netease_news()
    agent_reach_news = get_agent_reach_news()
    wallstreetcn_news = get_wallstreetcn_news()
    yicai_news = get_yicai_news()
    eastmoney_news = get_eastmoney_news()
    
    all_news.extend(sina_news)
    all_news.extend(tencent_news)
    all_news.extend(netease_news)
    all_news.extend(agent_reach_news)
    all_news.extend(wallstreetcn_news)
    all_news.extend(yicai_news)
    all_news.extend(eastmoney_news)
    
    # å»é‡
    seen_titles = set()
    unique_news = []
    for news in all_news:
        title = news.get('title', '')
        simple_title = ''.join(c for c in title if c.isalnum())[:15]
        if simple_title and simple_title not in seen_titles:
            seen_titles.add(simple_title)
            unique_news.append(news)
    
    print(f"  âœ… Exaå…¨ç½‘æœç´¢: {len(exa_news)}æ¡ [é«˜ä¼˜å…ˆçº§]")
    print(f"  âœ… æ–°æµªè´¢ç»: {len(sina_news)}æ¡")
    print(f"  âœ… è…¾è®¯è´¢ç»: {len(tencent_news)}æ¡")
    print(f"  âœ… ç½‘æ˜“è´¢ç»: {len(netease_news)}æ¡")
    print(f"  âœ… åå°”è¡—è§é—»: {len(wallstreetcn_news)}æ¡")
    print(f"  âœ… ç¬¬ä¸€è´¢ç»: {len(yicai_news)}æ¡")
    print(f"  âœ… ä¸œæ–¹è´¢å¯Œ: {len(eastmoney_news)}æ¡")
    print(f"  âœ… Agent Reach: {len(agent_reach_news)}æ¡")
    print(f"  âœ… å»é‡å: {len(unique_news)}æ¡")
    
    return unique_news[:35]


def analyze_news_impact(news_items, market='A+H'):
    """åˆ†ææ–°é—»å¯¹å¸‚åœºçš„å½±å“"""
    impact_factors = []
    
    # A+Hå¸‚åœºå…³é”®è¯æ˜ å°„
    keyword_mapping = {
        # æ”¿ç­–
        'æ”¿ç­–': {'sectors': ['é‡‘è', 'æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'æ”¿ç­–å½±å“', 'intensity': 3},
        'é™å‡†': {'sectors': ['é‡‘è', 'åœ°äº§'], 'impact': 'åˆ©å¥½', 'reason': 'æµåŠ¨æ€§å®½æ¾', 'intensity': 4},
        'é™æ¯': {'sectors': ['é‡‘è', 'åœ°äº§'], 'impact': 'åˆ©å¥½', 'reason': 'èµ„é‡‘æˆæœ¬ä¸‹é™', 'intensity': 4},
        'åˆºæ¿€': {'sectors': ['æ¶ˆè´¹', 'æ–°èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'ç»æµåˆºæ¿€æ”¿ç­–', 'intensity': 3},
        
        # ç§‘æŠ€
        'åŠå¯¼ä½“': {'sectors': ['åŠå¯¼ä½“è®¾å¤‡'], 'impact': 'å…³è”', 'reason': 'åŠå¯¼ä½“äº§ä¸šåŠ¨æ€', 'intensity': 4},
        'èŠ¯ç‰‡': {'sectors': ['åŠå¯¼ä½“è®¾å¤‡', 'AIç®—åŠ›'], 'impact': 'å…³è”', 'reason': 'èŠ¯ç‰‡äº§ä¸šé“¾', 'intensity': 4},
        'äººå·¥æ™ºèƒ½': {'sectors': ['AIç®—åŠ›'], 'impact': 'åˆ©å¥½', 'reason': 'AIäº§ä¸š', 'intensity': 4},
        'è‹±ä¼Ÿè¾¾': {'sectors': ['AIç®—åŠ›', 'åŠå¯¼ä½“è®¾å¤‡'], 'impact': 'å…³è”', 'reason': 'AIé¾™å¤´åŠ¨æ€', 'intensity': 5},
        'å…‰æ¨¡å—': {'sectors': ['å…‰é€šè®¯'], 'impact': 'åˆ©å¥½', 'reason': 'å…‰é€šè®¯äº§ä¸š', 'intensity': 4},
        '5G': {'sectors': ['å…‰é€šè®¯', 'åŠå¯¼ä½“è®¾å¤‡'], 'impact': 'åˆ©å¥½', 'reason': 'é€šä¿¡åŸºå»º', 'intensity': 3},
        
        # æ–°èƒ½æº
        'æ–°èƒ½æº': {'sectors': ['æ–°èƒ½æº'], 'impact': 'å…³è”', 'reason': 'æ–°èƒ½æºäº§ä¸š', 'intensity': 3},
        'ç”µåŠ¨è½¦': {'sectors': ['æ–°èƒ½æº'], 'impact': 'å…³è”', 'reason': 'ç”µåŠ¨è½¦åŠ¨æ€', 'intensity': 3},
        'å…‰ä¼': {'sectors': ['æ–°èƒ½æº'], 'impact': 'å…³è”', 'reason': 'å…‰ä¼äº§ä¸š', 'intensity': 3},
        'å‚¨èƒ½': {'sectors': ['æ–°èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'å‚¨èƒ½éœ€æ±‚', 'intensity': 3},
        
        # æ¶ˆè´¹
        'æ¶ˆè´¹': {'sectors': ['æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'æ¶ˆè´¹æ•°æ®', 'intensity': 3},
        'ç™½é…’': {'sectors': ['æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'ç™½é…’è¡Œä¸š', 'intensity': 3},
        'èŒ…å°': {'sectors': ['æ¶ˆè´¹'], 'impact': 'å…³è”', 'reason': 'ç™½é…’é¾™å¤´', 'intensity': 4},
        
        # åŒ»è¯
        'åŒ»è¯': {'sectors': ['åŒ»è¯', 'ç”Ÿç‰©åŒ»è¯'], 'impact': 'å…³è”', 'reason': 'åŒ»è¯äº§ä¸š', 'intensity': 3},
        'ç–«è‹—': {'sectors': ['åŒ»è¯', 'ç”Ÿç‰©åŒ»è¯'], 'impact': 'åˆ©å¥½', 'reason': 'ç–«è‹—éœ€æ±‚', 'intensity': 3},
        'åˆ›æ–°è¯': {'sectors': ['åŒ»è¯', 'ç”Ÿç‰©åŒ»è¯'], 'impact': 'åˆ©å¥½', 'reason': 'åˆ›æ–°è¯çªç ´', 'intensity': 4},
        
        # é‡‘è
        'é“¶è¡Œ': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'é“¶è¡Œä¸šåŠ¨æ€', 'intensity': 2},
        'åˆ¸å•†': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'åˆ¸å•†åŠ¨æ€', 'intensity': 3},
        'ä¿é™©': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'ä¿é™©è¡Œä¸š', 'intensity': 2},
        
        # æ¸¯è‚¡ç‰¹å®š
        'æ¸¯è‚¡': {'sectors': ['ç§‘æŠ€å·¨å¤´', 'ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'æ¸¯è‚¡å¸‚åœº', 'intensity': 3},
        'æ’æŒ‡': {'sectors': ['ç§‘æŠ€å·¨å¤´', 'é‡‘è'], 'impact': 'å…³è”', 'reason': 'æ’æŒ‡åŠ¨æ€', 'intensity': 3},
        'è…¾è®¯': {'sectors': ['ç§‘æŠ€å·¨å¤´'], 'impact': 'å…³è”', 'reason': 'è…¾è®¯åŠ¨æ€', 'intensity': 4},
        'é˜¿é‡Œ': {'sectors': ['ç§‘æŠ€å·¨å¤´', 'ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'é˜¿é‡ŒåŠ¨æ€', 'intensity': 4},
        'ç¾å›¢': {'sectors': ['ç§‘æŠ€å·¨å¤´'], 'impact': 'å…³è”', 'reason': 'ç¾å›¢åŠ¨æ€', 'intensity': 3},
        
        # å›½é™…
        'ç¾è‚¡': {'sectors': ['ç§‘æŠ€å·¨å¤´', 'ä¸­æ¦‚äº’è”'], 'impact': 'å…³è”', 'reason': 'ç¾è‚¡æ˜ å°„', 'intensity': 3},
        'çº³æ–¯è¾¾å…‹': {'sectors': ['ç§‘æŠ€å·¨å¤´', 'AIç®—åŠ›'], 'impact': 'å…³è”', 'reason': 'ç§‘æŠ€è‚¡æ˜ å°„', 'intensity': 4},
        'ç¾è”å‚¨': {'sectors': ['é‡‘è'], 'impact': 'å…³è”', 'reason': 'ç¾è”å‚¨æ”¿ç­–', 'intensity': 4},
        'åŠ æ¯': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'åˆ©ç©º', 'reason': 'èµ„é‡‘æˆæœ¬ä¸Šå‡', 'intensity': 4},
        'é™æ¯': {'sectors': ['é‡‘è', 'ç§‘æŠ€å·¨å¤´'], 'impact': 'åˆ©å¥½', 'reason': 'æµåŠ¨æ€§å®½æ¾', 'intensity': 4},
        'é€šèƒ€': {'sectors': ['æ¶ˆè´¹', 'é‡‘è'], 'impact': 'åˆ©ç©º', 'reason': 'é€šèƒ€å‹åŠ›', 'intensity': 3},
        
        # åœ°ç¼˜
        'å†²çª': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'åœ°ç¼˜é£é™©', 'intensity': 3},
        'æˆ˜äº‰': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'åœ°ç¼˜é£é™©', 'intensity': 4},
        'åŸæ²¹': {'sectors': ['èƒ½æº'], 'impact': 'å…³è”', 'reason': 'åŸæ²¹ä»·æ ¼', 'intensity': 4},
        'é»„é‡‘': {'sectors': ['èƒ½æº'], 'impact': 'åˆ©å¥½', 'reason': 'é¿é™©éœ€æ±‚', 'intensity': 3},
    }
    
    for news in news_items:
        title = news.get('title', '')
        for keyword, mapping in keyword_mapping.items():
            if keyword in title:
                intensity = mapping.get('intensity', 2)
                stars = "â­" * intensity + " " + ("é«˜" if intensity >= 4 else "ä¸­" if intensity >= 2 else "ä½")
                
                impact_factors.append({
                    'keyword': keyword,
                    'title': title[:40] + '...' if len(title) > 40 else title,
                    'sectors': mapping['sectors'],
                    'impact': mapping['impact'],
                    'reason': mapping['reason'],
                    'importance': stars,
                    'intensity': intensity,
                    'source': news.get('source', 'æ–°é—»')
                })
                break
    
    # æ’åºå¹¶å»é‡
    impact_factors.sort(key=lambda x: x.get('intensity', 0), reverse=True)
    
    seen_keywords = set()
    unique_factors = []
    for factor in impact_factors:
        if factor['keyword'] not in seen_keywords:
            seen_keywords.add(factor['keyword'])
            unique_factors.append(factor)
    
    return unique_factors[:8]


# ============================================
# å¸‚åœºåˆ†ææ¨¡å—
# ============================================

def analyze_a_sectors(quotes_dict):
    """åˆ†æAè‚¡æ¿å—å¼ºå¼±"""
    sector_data = {}
    
    for sector_name, sector_info in A_SECTORS.items():
        stocks = []
        for symbol in sector_info['stocks']:
            if symbol in quotes_dict:
                q = quotes_dict[symbol]
                stocks.append({
                    'symbol': symbol,
                    'name': sector_info['leaders'][sector_info['stocks'].index(symbol)] if symbol in sector_info['stocks'] else symbol,
                    'price': q.get('price', 0),
                    'change': q.get('change', 0),
                })
        
        if stocks:
            avg_change = sum(s['change'] for s in stocks) / len(stocks)
            stocks_sorted = sorted(stocks, key=lambda x: x['change'], reverse=True)
            leader = stocks_sorted[0] if stocks_sorted else None
            
            sector_data[sector_name] = {
                'avg_change': avg_change,
                'up_count': sum(1 for s in stocks if s['change'] > 0),
                'total': len(stocks),
                'stocks': stocks,
                'leader': leader
            }
    
    return sorted(sector_data.items(), key=lambda x: x[1]['avg_change'], reverse=True)


def analyze_h_sectors(quotes_dict):
    """åˆ†ææ¸¯è‚¡æ¿å—å¼ºå¼±"""
    sector_data = {}
    
    for sector_name, sector_info in H_SECTORS.items():
        stocks = []
        for symbol in sector_info['stocks']:
            if symbol in quotes_dict:
                q = quotes_dict[symbol]
                stocks.append({
                    'symbol': symbol,
                    'name': sector_info['leaders'][sector_info['stocks'].index(symbol)] if symbol in sector_info['stocks'] else symbol,
                    'price': q.get('price', 0),
                    'change': q.get('change', 0),
                })
        
        if stocks:
            avg_change = sum(s['change'] for s in stocks) / len(stocks)
            stocks_sorted = sorted(stocks, key=lambda x: x['change'], reverse=True)
            leader = stocks_sorted[0] if stocks_sorted else None
            
            sector_data[sector_name] = {
                'avg_change': avg_change,
                'up_count': sum(1 for s in stocks if s['change'] > 0),
                'total': len(stocks),
                'stocks': stocks,
                'leader': leader
            }
    
    return sorted(sector_data.items(), key=lambda x: x[1]['avg_change'], reverse=True)


def get_us_market_summary():
    """è·å–ç¾è‚¡éš”å¤œå›é¡¾ï¼ˆè¯»å–æœ€æ–°ç¾è‚¡æŠ¥å‘Šï¼‰"""
    try:
        today = datetime.now().strftime('%Y%m%d')
        report_file = f"/root/.openclaw/workspace/data/us_market_daily_{today}.md"
        
        if os.path.exists(report_file):
            with open(report_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–å…³é”®ä¿¡æ¯
            summary = {
                'loaded': True,
                'indices': [],
                'top_sectors': [],
                'key_drivers': []
            }
            
            # ç®€åŒ–å¤„ç†ï¼Œè¿”å›æŠ¥å‘Šè·¯å¾„
            return {'loaded': True, 'file': report_file}
        else:
            return {'loaded': False, 'file': None}
    except Exception as e:
        return {'loaded': False, 'error': str(e)}


# ============================================
# æŠ¥å‘Šç”Ÿæˆ
# ============================================

def generate_report():
    """ç”ŸæˆA+Hå¼€ç›˜å‰ç»æ·±åº¦æŠ¥å‘Š"""
    print("ğŸŒ… A+Hè‚¡å¼€ç›˜å‰ç» v2.0 æ·±åº¦åˆ†æ")
    print("=" * 60)
    
    now = datetime.now()
    today_str = now.strftime('%Y-%m-%d')
    
    # 1. è·å–æ–°é—»
    news_items = get_international_news()
    news_factors = analyze_news_impact(news_items)
    print(f"âœ… è¯†åˆ« {len(news_factors)} ä¸ªæ–°é—»é©±åŠ¨å› å­")
    
    # 2. è·å–ç¾è‚¡å›é¡¾
    print("\nğŸ“Š è·å–ç¾è‚¡éš”å¤œå›é¡¾...")
    us_summary = get_us_market_summary()
    if us_summary['loaded']:
        print(f"  âœ… å·²åŠ è½½ç¾è‚¡æŠ¥å‘Š: {us_summary['file']}")
    else:
        print("  âš ï¸ ç¾è‚¡æŠ¥å‘Šæœªç”Ÿæˆ")
    
    # 3. è·å–A+Hè¡Œæƒ…
    print("\nğŸ“ˆ è·å–A+Hè‚¡è¡Œæƒ…...")
    api = get_longbridge_api()
    
    all_a_symbols = []
    for sector in A_SECTORS.values():
        all_a_symbols.extend(sector['stocks'])
    
    all_h_symbols = []
    for sector in H_SECTORS.values():
        all_h_symbols.extend(sector['stocks'])
    
    all_symbols = list(set(all_a_symbols + all_h_symbols))
    quotes = api.get_quotes(all_symbols)
    quotes_dict = {q['symbol']: q for q in quotes}
    print(f"  âœ… è·å–åˆ° {len(quotes)} åªè‚¡ç¥¨è¡Œæƒ…")
    
    # 4. åˆ†ææ¿å—
    print("\nğŸ” åˆ†æAè‚¡æ¿å—...")
    a_sectors = analyze_a_sectors(quotes_dict)
    print(f"  âœ… åˆ†æå®Œæˆï¼Œå…± {len(a_sectors)} ä¸ªæ¿å—")
    
    print("\nğŸ” åˆ†ææ¸¯è‚¡æ¿å—...")
    h_sectors = analyze_h_sectors(quotes_dict)
    print(f"  âœ… åˆ†æå®Œæˆï¼Œå…± {len(h_sectors)} ä¸ªæ¿å—")
    
    # æ”¶é›†æ‰€æœ‰è‚¡ç¥¨
    all_a_stocks = []
    for sector_name, sector_info in a_sectors:
        for stock in sector_info['stocks']:
            all_a_stocks.append({**stock, 'sector': sector_name})
    
    all_h_stocks = []
    for sector_name, sector_info in h_sectors:
        for stock in sector_info['stocks']:
            all_h_stocks.append({**stock, 'sector': sector_name})
    
    # 5. äº®ç‚¹/æ‹–ç´¯ä¸ªè‚¡
    a_gainers = sorted(all_a_stocks, key=lambda x: x['change'], reverse=True)[:5]
    a_losers = sorted(all_a_stocks, key=lambda x: x['change'])[:5]
    h_gainers = sorted(all_h_stocks, key=lambda x: x['change'], reverse=True)[:5]
    h_losers = sorted(all_h_stocks, key=lambda x: x['change'])[:5]
    
    # 6. ç”ŸæˆæŠ¥å‘Š
    report_lines = [
        f"# ğŸŒ… A+Hè‚¡å¼€ç›˜å‰ç»æŠ¥å‘Š v2.0",
        f"",
        f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {now.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**æ•°æ®æ—¥æœŸ**: {today_str}",
        f"**åˆ†ææ¡†æ¶**: ç¾è‚¡å›é¡¾ + Aè‚¡æ¿å— + æ¸¯è‚¡æ¿å— + æ–°é—»é©±åŠ¨",
        f"",
        f"---",
        f"",
        f"## ä¸€ã€éš”å¤œç¾è‚¡å›é¡¾",
        f"",
    ]
    
    if us_summary['loaded']:
        report_lines.append(f"âœ… **ç¾è‚¡æŠ¥å‘Šå·²ç”Ÿæˆ**: å‚è§ `us_market_daily_{today_str}.md`")
        report_lines.append(f"")
        report_lines.append(f"**æ ¸å¿ƒç»“è®º**: å‚è§ç¾è‚¡æŠ¥å‘Šã€Œå¸‚åœºå±•æœ›ä¸æ€»ç»“ã€éƒ¨åˆ†")
    else:
        report_lines.append(f"âš ï¸ **ç¾è‚¡æŠ¥å‘Šå°šæœªç”Ÿæˆ**ï¼Œå»ºè®®å…ˆç”Ÿæˆç¾è‚¡æŠ¥å‘Š")
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## äºŒã€Aè‚¡æ¿å—å¼ºå¼±æ’åº",
        f"",
        f"| æ’å | æ¿å— | å¹³å‡æ¶¨è·Œ | ä¸ªè‚¡æ•° | é¢†æ¶¨è‚¡ |",
        f"|------|------|----------|--------|--------|"
    ])
    
    for i, (sector_name, sector_info) in enumerate(a_sectors, 1):
        emoji = get_emoji(sector_info['avg_change'])
        rank = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
        leader = sector_info['leader']
        leader_str = f"{leader['name']} {format_change(leader['change'])}" if leader else "-"
        
        report_lines.append(
            f"| {rank} | {emoji} {sector_name} | {format_change(sector_info['avg_change'])} | {sector_info['total']}åª | {leader_str} |"
        )
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## ä¸‰ã€æ¸¯è‚¡æ¿å—å¼ºå¼±æ’åº",
        f"",
        f"| æ’å | æ¿å— | å¹³å‡æ¶¨è·Œ | ä¸ªè‚¡æ•° | é¢†æ¶¨è‚¡ |",
        f"|------|------|----------|--------|--------|"
    ])
    
    for i, (sector_name, sector_info) in enumerate(h_sectors, 1):
        emoji = get_emoji(sector_info['avg_change'])
        rank = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i}."
        leader = sector_info['leader']
        leader_str = f"{leader['name']} {format_change(leader['change'])}" if leader else "-"
        
        report_lines.append(
            f"| {rank} | {emoji} {sector_name} | {format_change(sector_info['avg_change'])} | {sector_info['total']}åª | {leader_str} |"
        )
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## å››ã€æ–°é—»é©±åŠ¨å› å­ï¼ˆéš”å¤œ+Aè‚¡å¼€ç›˜ï¼‰",
        f"",
        f"| é©±åŠ¨å› å­ | é‡è¦åº¦ | å½±å“æ¿å— | é€»è¾‘ | æ¥æº |",
        f"|----------|--------|----------|------|------|"
    ])
    
    for factor in news_factors[:6]:
        report_lines.append(
            f"| {factor['keyword']} | {factor['importance']} | {'/'.join(factor['sectors'])} | {factor['reason']} | {factor['source']} |"
        )
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## äº”ã€å¼€ç›˜ç­–ç•¥å»ºè®®",
        f"",
        f"### Aè‚¡ç­–ç•¥",
        f"",
        f"| æ¿å— | æ“ä½œ | å»ºè®® |",
        f"|------|------|------|"
    ])
    
    for sector_name, sector_info in a_sectors:
        action, advice = get_action_emoji(sector_info['avg_change'])
        report_lines.append(f"| {sector_name} | {action} | {advice} |")
    
    report_lines.extend([
        f"",
        f"### æ¸¯è‚¡ç­–ç•¥",
        f"",
        f"| æ¿å— | æ“ä½œ | å»ºè®® |",
        f"|------|------|------|"
    ])
    
    for sector_name, sector_info in h_sectors:
        action, advice = get_action_emoji(sector_info['avg_change'])
        report_lines.append(f"| {sector_name} | {action} | {advice} |")
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## å…­ã€é‡ç‚¹ä¸ªè‚¡ç›‘æ§",
        f"",
        f"### Aè‚¡",
        f"",
        f"**ğŸ”¥ æ¶¨å¹…å‰5**:"
    ])
    
    for stock in a_gainers:
        emoji = "ğŸš€" if stock['change'] > 5 else "ğŸ“ˆ"
        report_lines.append(f"- {emoji} {stock['name']}({stock['symbol']}): {format_change(stock['change'])} - {stock['sector']}")
    
    report_lines.append(f"")
    report_lines.append(f"**ğŸ”» è·Œå¹…å‰5**:")
    
    for stock in a_losers:
        emoji = "ğŸ”»" if stock['change'] < -5 else "ğŸ“‰"
        report_lines.append(f"- {emoji} {stock['name']}({stock['symbol']}): {format_change(stock['change'])} - {stock['sector']}")
    
    report_lines.extend([
        f"",
        f"### æ¸¯è‚¡",
        f"",
        f"**ğŸ”¥ æ¶¨å¹…å‰5**:"
    ])
    
    for stock in h_gainers:
        emoji = "ğŸš€" if stock['change'] > 5 else "ğŸ“ˆ"
        report_lines.append(f"- {emoji} {stock['name']}({stock['symbol']}): {format_change(stock['change'])} - {stock['sector']}")
    
    report_lines.append(f"")
    report_lines.append(f"**ğŸ”» è·Œå¹…å‰5**:")
    
    for stock in h_losers:
        emoji = "ğŸ”»" if stock['change'] < -5 else "ğŸ“‰"
        report_lines.append(f"- {emoji} {stock['name']}({stock['symbol']}): {format_change(stock['change'])} - {stock['sector']}")
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## ğŸ“Œ æ•°æ®æ¥æº",
        f"",
        f"- **è¡Œæƒ…æ•°æ®**: é•¿æ¡¥API (Longbridge OpenAPI)",
        f"- **ç¾è‚¡å›é¡¾**: å¼•ç”¨ç¾è‚¡å¸‚åœºæ·±åº¦åˆ†ææŠ¥å‘Š",
        f"- **æ–°é—»æ•°æ®**: æ–°æµªè´¢ç»API + è…¾è®¯è´¢ç»API + ç½‘æ˜“è´¢ç»",
        f"- **æ–°é—»åˆ†æ**: å…³é”®è¯åŒ¹é…ï¼ˆ50+å…³é”®è¯ï¼‰",
        f"",
        f"---",
        f"",
        f"âš ï¸ **é£é™©æç¤º**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚",
        f"",
        f"ğŸ“… **ä¸‹æ¬¡æŠ¥å‘Š**: 15:00 æ”¶ç›˜æ·±åº¦åˆ†æ"
    ])
    
    report = "\n".join(report_lines)
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = f"/root/.openclaw/workspace/data/ah_market_preopen_{today_str}.md"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    print("\n" + "=" * 60)
    print(report[:1500])
    print("\n... [æŠ¥å‘Šå·²æˆªæ–­] ...")
    
    # å‘é€åˆ°é£ä¹¦
    print("\nğŸ“¤ æ­£åœ¨å‘é€åˆ°é£ä¹¦...")
    send_feishu_message(report, "ğŸŒ… A+Hè‚¡å¼€ç›˜å‰ç»æŠ¥å‘Š v2.0")
    
    return report


if __name__ == "__main__":
    generate_report()
